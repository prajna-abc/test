url,uuid,file,summary,paper_title,year,source,camera_modality,visual_feature_types,impairment_type,real_time_capability,sample_size,environment,primary_accuracy_metric,relevance_score,relevance_reason,details_json
https://arxiv.org/pdf/2209.01657,f7f12a3e-78ff-4f1d-944b-d5e9b8215fb5,f7f12a3e-78ff-4f1d-944b-d5e9b8215fb5.json,"This paper presents a novel method for detecting alcohol consumption using periocular near-infrared (NIR) images and a Fused Capsule Network (F-CapsNet) architecture. The approach leverages changes in iris and pupil dynamics caused by alcohol's effects on the central nervous system. A new dataset of 3,000 NIR images from 30 volunteers (with and without alcohol) was collected under controlled conditions. The proposed F-CapsNet achieved a high accuracy of 92.3%, outperforming traditional CNN and SVM baselines, and is suitable for real-time and mobile deployment due to its reduced parameter count. The study demonstrates the feasibility of camera-based, real-time alcohol impairment detection using NIR imaging.",Alcohol Consumption Detection from Periocular NIR Images Using Capsule Network,2022,ICPR 2022 / arXiv:2209.01657,IR/NIR,Eye,alcohol,Yes (architecture designed for real-time and mobile deployment),"30 subjects, 3,000 NIR images (expanded to 12,000 with augmentation)","Controlled indoor environment (constant lighting, fixed camera distances, NIR sensors)",Accuracy (92.3% with F-CapsNet),⭐⭐⭐,"Directly addresses real-time alcohol impairment detection using NIR camera images and advanced deep learning, with a new dataset and high reported accuracy.","{""dataset"": {""name"": ""IAL-I"", ""availability"": ""Available upon request"", ""composition"": ""30 volunteers (24 male, 6 female), ages 25-50, 5 sessions (pre- and post-alcohol at 15, 30, 45, 60 min), 10 images per eye per session"", ""capture_devices"": ""TD-100 and Iritech NIR cameras"", ""protocol"": ""Controlled lighting (200 lux), fixed distances (30cm, 50cm), 200ml alcohol (42%) consumed, images captured at intervals""}, ""algorithm"": {""name"": ""Fused Capsule Network (F-CapsNet)"", ""architecture"": ""Convolutional block for feature extraction per class, features fused and input to two-layer capsule network, decoder for regularization"", ""parameters"": ""9M (half of standard CapsNet)"", ""data_augmentation"": ""Rotation, shift, zoom (imgaug library), dataset expanded to 12,000 images per eye""}, ""comparisons"": [{""method"": ""SVM"", ""accuracy"": ""63.5%""}, {""method"": ""Small-VGG CNN"", ""accuracy"": ""73.4%""}, {""method"": ""ArcFace embedding + SVM"", ""accuracy"": ""73.0%""}, {""method"": ""ResNet50"", ""accuracy"": ""73.8%""}, {""method"": ""Traditional CapsNet"", ""accuracy"": ""91.3%""}, {""method"": ""F-CapsNet"", ""accuracy"": ""92.3%""}], ""feature_analysis"": {""manual_features"": ""Pupil/iris radius ratio (p), not sufficient alone for classification"", ""deep_features"": ""CNN and F-CapsNet focus on iris and periocular regions; GradCAM++ used for visualization""}, ""limitations"": [""Only NIR images; no multi-modal fusion"", ""Sample size moderate (30 subjects)"", ""Controlled environment; real-world generalization not tested""], ""potential_applications"": [""Fitness for Duty (FFD) assessment"", ""Workplace safety (mining, logistics, health)"", ""Mobile/embedded real-time impairment detection""]}"
https://arxiv.org/pdf/2304.11858,97fe60ab-8c49-460d-a3a4-bcb0873af3e8,97fe60ab-8c49-460d-a3a4-bcb0873af3e8.json,"This paper presents a CNN-LSTM approach for classifying fitness-for-duty (FFD) status using temporal sequences of near-infrared (NIR) periocular images. The system detects impairment due to alcohol, drugs, and sleepiness by analyzing spatial and temporal features of the iris and periocular region. Evaluated on a large dataset (FFD-NIR-Seq) with 980 subjects, the method achieves high accuracy, especially for alcohol and drug impairment, and demonstrates potential for real-time, non-invasive workplace screening.",Fitness-for-Duty Classification using Temporal Sequences of Iris Periocular images,2023,"arXiv:2304.11858v1 [cs.CV], IEEE",IR/NIR,Eye,"alcohol, cannabis, general impairment, fatigue",Potential for real-time; not explicitly demonstrated but model is lightweight and designed for practical deployment,"980 subjects; 132,555 image sequences (8 frames each)",Controlled indoor environment; subjects standing in front of NIR camera,"Precision (Fit: 81.4%, Unfit: 96.9%), Overall accuracy: 88.3%, EER for sleepiness: 18.6%",⭐⭐⭐,"Highly relevant: Uses NIR camera for real-time-capable visual detection of alcohol, drug, and fatigue impairment via eye/iris dynamics; large dataset and state-of-the-art deep learning approach.","{""dataset"": {""name"": ""FFD-NIR-Seq"", ""composition"": ""980 subjects, 4 classes (control, alcohol, drug, sleep), 75-150 frames per subject, 15 fps, 630x360 px images"", ""public_availability"": ""Not specified""}, ""model_architecture"": {""cnn"": ""VGG16-inspired, extracts spatial features from each frame"", ""lstm"": ""2-layer LSTM, 32 hidden units, captures temporal dependencies across 8-frame sequences"", ""input_shape"": ""8x210x140x3 (sub-sequence of 8 frames, resized)"", ""framework"": ""TensorFlow""}, ""classification_labels"": [""Control (fit)"", ""Alcohol (unfit)"", ""Drug (unfit)"", ""Sleep (unfit)""], ""metrics"": {""fit_precision"": ""81.4%"", ""unfit_precision"": ""96.9%"", ""alcohol_accuracy"": ""90.6%"", ""drug_accuracy"": ""100%"", ""sleep_accuracy"": ""51.6%"", ""overall_accuracy"": ""88.3%"", ""EER_sleep"": ""18.6%"", ""FNR10_sleep"": ""22.5%"", ""FNR20_sleep"": ""25.3%""}, ""limitations"": [""Sleepiness is harder to detect (lower accuracy)"", ""Some overlap between impairment classes (e.g., alcohol and sleepiness)"", ""No explicit real-time deployment, but model is lightweight"", ""Non-visual methods (e.g., ECG) mentioned only as comparison""], ""deployment_notes"": {""hardware"": ""Standard NIR iris camera"", ""processing"": ""Batch processing of 8-frame sequences; model designed for efficiency"", ""future_work"": ""Mobile/embedded deployment, improved sleepiness detection, sequence-based data augmentation""}}"
https://ijsart.com/public/storage/paper/pdf/IJSARTV10I489706.pdf,a0b2fd86-bf88-4c6a-b43d-47a6659aed48,a0b2fd86-bf88-4c6a-b43d-47a6659aed48.json,"This paper proposes an automated system for detecting drug-induced impairment by analyzing eye images using image processing and deep learning (CNNs). The approach focuses on segmenting and highlighting reddish areas in the sclera, which are indicative of drug consumption. The system is designed for rapid, accurate detection and aims to reduce reliance on manual expert observation. While the paper emphasizes real-time capability and practical deployment, it does not specify the exact dataset size or provide quantitative accuracy metrics.",Drugged Eye Detection Using Image Processing,2024,IJSART - Volume 10 Issue 4 – APRIL 2024,RGB,Eye,"general impairment, mixed",Claimed (few seconds per result),Not specified,Not specified (implied general/industrial use),Not specified (claims high accuracy),⭐⭐,"The paper directly addresses camera-based visual detection of drug-induced impairment using deep learning and image processing, focusing on eye features. However, lack of quantitative results, sample size, and real-world deployment details limits its top relevance.","{""methodology"": {""preprocessing"": ""Image resizing, noise reduction"", ""segmentation"": ""CNN-based segmentation to isolate reddish/infected eye regions"", ""feature_extraction"": ""Extraction of features from segmented eye regions"", ""classification"": ""CNN-based classification to detect drugged eyes""}, ""claimed_advantages"": [""High accuracy"", ""Rapid detection (few seconds)"", ""Works with low and high pixel images"", ""Reduces need for expert consultation""], ""limitations"": [""No quantitative accuracy or sample size reported"", ""No real-world deployment or dataset details"", ""Focuses only on visual (RGB) features; does not address other camera modalities""], ""future_work"": [""Web integration for broader deployment"", ""Incorporation of additional machine learning algorithms""], ""application_context"": ""Aimed at industrial and public health settings for rapid, automated detection of drug-induced impairment via eye analysis""}"
https://arxiv.org/pdf/2209.01683,a90b5ebf-0f17-4a72-bbc8-7bdd6f1223da,a90b5ebf-0f17-4a72-bbc8-7bdd6f1223da.json,"This paper presents a deep learning-based method for detecting fitness for duty (FFD) impairments (alcohol, drugs, sleep deprivation) using near-infrared (NIR) periocular iris images. The authors introduce a new NIR iris image database and propose a modified MobileNetV2 architecture to classify subjects as Fit or Unfit based on visual features related to iris and pupil dynamics. The system achieves high accuracy, especially for alcohol and drug-induced impairment, and demonstrates potential for real-time, contactless, camera-based impairment detection in industrial and safety-critical environments.",Learning to Predict Fitness for Duty using Near Infrared Periocular Iris Images,2022,"arXiv:2209.01683v1 [cs.CV], submitted to Journal of LaTeX Class Files",IR/NIR,Eye,"alcohol, cannabis, general impairment, fatigue",Yes (designed for real-time/near real-time operation on standard NIR iris capture devices),"1,510 eye-disjoint subjects, 144,011 images (average 150 images per subject)","Controlled indoor environment (constant lighting, 200 lux); industrial/laboratory setting","Detection accuracy (91.3% for alcohol, 99.1% for drugs, 72.4% for sleepiness); EER (as low as 7.6% for alcohol)",⭐⭐⭐,"Highly relevant: Uses NIR camera images for real-time detection of alcohol, drug, and fatigue impairment via visual analysis of iris/pupil dynamics. Large dataset, robust evaluation, and explicit focus on camera-based, contactless impairment detection.","{""database"": {""name"": ""FFD NIR iris images Stream database (FFD-NIR-Stream)"", ""availability"": ""Available upon request for research purposes"", ""devices"": [""Iritech MK2120UL (monocular)"", ""iCAM TD-100A"", ""Iritech Gemini"", ""Iritech Gemini-Venus""], ""conditions"": [""Control (no impairment)"", ""Alcohol (200ml, 42% concentration, multiple time points)"", ""Drugs (mainly cannabis, some tranquilizers, heroin, ecstasy)"", ""Sleep deprivation (various levels, monitored by smart band)""], ""image_type"": ""Periocular NIR images (both eyes, iris, pupil, sclera)""}, ""method"": {""architecture"": ""Modified MobileNetV2 (trained from scratch and fine-tuned variants)"", ""input"": ""Cropped periocular NIR images (448x448 px)"", ""feature_extraction"": ""Automatic via MobileNetV2; focus on iris and pupil dynamics"", ""classification"": ""Multi-class (Fit, Alcohol, Drug, Sleepiness); also binary Fit/Unfit""}, ""data_processing"": {""preprocessing"": ""Contrast-limited adaptive histogram equalization (CLAHE)"", ""data_augmentation"": ""Three-level DA: blurring, Gaussian noise, occlusion, zoom, etc."", ""class balancing"": ""Weighted loss function to address class imbalance""}, ""evaluation"": {""metrics"": [""Detection accuracy"", ""Equal Error Rate (EER)"", ""False Positive Rate (FPR)"", ""False Negative Rate (FNR)"", ""DET curves""], ""results"": {""alcohol"": ""91.3% accuracy, EER 7.6%"", ""drugs"": ""99.1% accuracy, EER 10.01%"", ""sleepiness"": ""72.4% accuracy, EER 15.24%"", ""Fit/Unfit (binary)"": ""94.0% (Fit), 84.0% (Unfit)""}}, ""limitations"": [""Sleepiness detection is more challenging and less accurate than alcohol/drug detection."", ""Non-visual methods (e.g., EEG, PVT) are discussed in related work but not used in this approach."", ""Database is controlled; real-world deployment may face additional challenges.""], ""deployment"": {""hardware_requirements"": ""Standard NIR iris capture devices; designed for mobile/embedded use"", ""potential_applications"": [""Industrial safety"", ""Transportation (drivers, pilots)"", ""Workplace fitness-for-duty screening""]}, ""future_work"": [""Expand sleepiness dataset"", ""Explore R-CNN and LSTM for temporal sequence modeling"", ""Real-world field trials""]}"
https://www.researchgate.net/publication/228522740_Iris_Recognition_under_Alcohol_Influence_A_Preliminary_Study,b3386a33-bbd0-463c-890b-2c186f7376f4,b3386a33-bbd0-463c-890b-2c186f7376f4.json,"This paper investigates the impact of alcohol consumption on iris recognition performance using near-infrared (NIR) imaging. The authors introduce the IIITD Iris Under Alcohol Influence (IUAI) database, containing pre- and post-alcohol iris images from 55 subjects. They analyze changes in pupil dilation/constriction and demonstrate that alcohol-induced changes can significantly affect iris recognition accuracy, with about 20% increased overlap between genuine and impostor match score distributions. The study highlights the vulnerability of iris biometrics to alcohol-induced physiological changes and suggests the need for next-generation systems to address this covariate.",Iris Recognition under Alcohol Influence: A Preliminary Study,2012,International Conference on Image Processing (ICIP),IR/NIR,Eye,alcohol,"No (offline analysis, but methods could be adapted for real-time)","55 subjects (110 unique irises, 220 pre- and 220 post-alcohol images)","Semi-controlled (constant room temperature and lighting, NIR iris scanner)","Verification accuracy (e.g., 97.7% for pre-post alcohol images with VeriEye); overlap in match score distributions; ROC curves",⭐⭐,"Directly studies visual (NIR) features for alcohol-induced impairment, but focuses on biometric vulnerability rather than real-time intoxication detection. No real-time implementation, but provides foundational insights for camera-based detection.","{""database"": ""IIITD Iris Under Alcohol Influence (IUAI) database; 55 subjects, 110 irises, images captured pre- and post-alcohol consumption (200ml, 42% alcohol, 15-20 min after consumption)."", ""imaging_device"": ""Vista iris scanner (NIR domain)."", ""feature_extraction"": ""Elliptical modeling of pupil and iris boundaries; calculation of dilation/constriction extent."", ""algorithms"": [""2D log polar Gabor wavelet feature encoding + SVM matching (Vatsa et al. 2008)"", ""VeriEye commercial iris recognition system""], ""key_findings"": [""Alcohol led to pupil dilation in ~51% and constriction in ~49% of cases."", ""About 28% of cases showed extent of change outside tolerance, reducing recognition confidence."", ""Overlap between genuine and impostor match score distributions increased by ~20% for pre-post alcohol comparisons."", ""Verification accuracy dropped slightly for pre-post alcohol images (e.g., VeriEye: 99.1% pre-pre, 98.6% post-post, 97.7% pre-post).""], ""limitations"": [""No real-time detection; focus is on biometric system vulnerability."", ""Only NIR imaging; no RGB or other modalities."", ""Small sample size; results are preliminary.""], ""potential_applications"": [""Could inform real-time intoxication detection by monitoring pupil dynamics with NIR cameras."", ""Highlights need for robustness in biometric systems under substance influence.""]}"
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9502109,3d585578-d19a-4a25-8fb9-6ef623ffc384,3d585578-d19a-4a25-8fb9-6ef623ffc384.json,"This paper presents a novel framework for detecting and segmenting periocular regions in near-infrared (NIR) eye images to assess alcohol-induced impairment. The approach leverages lightweight deep learning models (DenseNet10 and CCNet) for real-time semantic segmentation of the iris and pupil, enabling precise measurement of pupil and iris diameters. A large, manually labeled NIR eye image dataset under alcohol and non-alcohol conditions was created for this study. The system demonstrates high segmentation accuracy and is suitable for real-time deployment on mobile or embedded devices, making it highly relevant for camera-based intoxication detection.",Semantic Segmentation of Periocular Near-Infra-Red Eye Images Under Alcohol Effects,2021,"IEEE Access, DOI: 10.1109/ACCESS.2021.3101256",IR/NIR,Eye,alcohol,"Yes (lightweight models, suitable for real-time on embedded/mobile devices)","266 subjects (alcohol), 765 subjects (no alcohol), >21,000 images",Controlled indoor environment with constant lighting and temperature; NIR sensors at 30–50 cm distance,Mean Intersection-over-Union (IoU) of 94.54% (DenseNet10); pupil/iris localization error <1 pixel,⭐⭐⭐,"The study directly addresses real-time, camera-based detection of alcohol impairment using NIR imaging and visual features, with a large dataset, high accuracy, and practical deployment considerations.","{""dataset"": {""description"": ""Manually labeled NIR eye image database with >21,000 images, including both alcohol and non-alcohol conditions."", ""sensors"": [""Iritech Gemini"", ""Iritech Venus""], ""image_size"": ""1280x760 pixels"", ""labeling"": ""Pupil, iris, and sclera manually annotated for both eyes.""}, ""segmentation_framework"": {""eye_detection"": ""Custom Eye-tiny-yolo (YOLO-based) detector for simultaneous detection of both eyes in periocular NIR images."", ""segmentation_models"": [""DenseNet10 (122,514 parameters)"", ""CCNet (Criss-Cross Attention Network, 210,732 parameters)"", ""DeepVOGv2 (for comparison)""], ""data_augmentation"": ""Aggressive non-geometric augmentation (noise, blur, corruption) to improve robustness.""}, ""feature_extraction"": {""pupil/iris localization"": ""Mass Center, Least-Mean-Squares (LMS), and Mixed approaches for precise circle fitting."", ""metrics"": ""Pupil-iris ratio, temporal dynamics over 100 frames per subject.""}, ""impairment detection"": {""alcohol_behavior_curve"": ""Grand mean analysis of pupil size over time to distinguish alcohol vs. non-alcohol groups."", ""challenges"": [""Variability in pupil response to alcohol"", ""Semi-closed eyes and eyelash occlusion"", ""Motion blur due to subject instability""]}, ""limitations"": [""No gender analysis performed"", ""No direct blood alcohol measurement; relies on visual/behavioral cues""], ""deployment"": {""hardware"": ""Tested on GPU workstations; models designed for low memory footprint suitable for embedded/mobile NIR sensors."", ""real_time"": ""Segmentation and detection pipeline designed for real-time operation.""}, ""comparison"": {""baselines"": [""Osiris (parametric, fails under alcohol-induced pupil changes)"", ""DeepVOG (pretrained, lower accuracy than custom models)""]}, ""future_work"": [""Public release of the NIR alcohol eye image database"", ""Extension to general fitness-for-duty assessment using regular NIR iris sensors""]}"
https://pmc.ncbi.nlm.nih.gov/articles/PMC11748063/,80782a95-1c39-4ad8-bec1-02c4f632bc87,80782a95-1c39-4ad8-bec1-02c4f632bc87.json,"This clinical study evaluated the feasibility of using consumer-grade smartphone cameras to detect intoxication from four drug classes (oxycodone, lorazepam, lisdexamphetamine, and cannabis) in healthy volunteers. By analyzing eye reactions—specifically pupillary light reflex, convergence, nystagmus, and scleral redness—under controlled lighting, the study demonstrated that distinct, drug-specific ocular patterns can be reliably captured and quantified using AI-based video analysis. The approach shows strong promise for real-time, self-administered, camera-based impairment detection, though further validation in real-world and polysubstance scenarios is needed.",Eye reactions under the influence of drugs of abuse as measured by smartphones: a controlled clinical study in healthy volunteers,2025,Frontiers in Neuroscience,RGB,Eye,"opioids, benzodiazepines, cannabis, central stimulants","Yes (5–10 min per test, AI-based video analysis on smartphone)",48 (12 per drug group),"Controlled indoor laboratory, two ambient light levels (~50 lux, ~500 lux)","Statistical significance (Wilcoxon rank test, p < 0.01 for all drugs vs. baseline); 87–97% of video data yielded usable features",⭐⭐⭐,"Directly demonstrates real-time, camera-based intoxication detection for multiple drug classes using consumer smartphones, with robust feature extraction and statistical validation.","{""study_design"": ""Randomized, parallel, open-label feasibility trial; single center; healthy volunteers; controlled dosing of four drug classes."", ""camera_devices"": [""Samsung S22"", ""iPhone 13 mini""], ""app_platform"": ""Previct Drugs App (Kontigo Care AB), with AI-based video analysis and voice guidance."", ""eye_tests"": [""Pupillary Light Reflex (PLR) using back camera and phone flashlight"", ""Non-convergence (NC) using front camera"", ""Horizontal Nystagmus (NY) using front camera""], ""feature_extraction"": ""AI models (initial and refined) extracted 24 key features per test, including pupil size, contraction velocity, latency, convergence, nystagmus count/mass, and scleral redness."", ""ambient_light_control"": ""Two lighting conditions (~50 lux and ~500 lux) with smart lighting and luminometer validation."", ""statistical_analysis"": ""Wilcoxon rank test for baseline vs. intoxicated state; discriminant principal component analysis (PCA) for feature separation."", ""drug_doses"": {""oxycodone"": ""20 mg oral"", ""lorazepam"": ""2 mg oral"", ""lisdexamphetamine"": ""70 mg oral (metabolized to ~20 mg dexamphetamine)"", ""cannabis"": ""65 mg inhaled (22% THC, ~5 mg bioavailable)""}, ""test_duration"": ""Each self-administered test took 5–10 minutes; three tests per session."", ""data_quality"": ""87–97% of acquired videos yielded usable features; failures mostly due to inability to keep eyes open (e.g., with lorazepam)."", ""key_findings"": {""oxycodone"": ""Significant pupil constriction (miosis), effect lasting at least 5h."", ""lorazepam"": ""Impaired convergence (non-convergence), some nystagmus."", ""lisdexamphetamine"": ""Significant pupil dilation (mydriasis)."", ""cannabis"": ""Miosis, reduced light-induced amplitude, increased scleral redness, some nystagmus.""}, ""limitations"": [""Controlled lab setting; not tested in real-world or outdoor environments."", ""Healthy volunteers, not SUD patients; only therapeutic doses."", ""No assessment of polysubstance use or chronic intoxication."", ""Ambient light must be measured and accounted for in models."", ""Indirect method—cannot legally confirm specific drug use without chemical analysis.""], ""usability"": ""98% of participants rated the app as positive or very positive for self-administration."", ""ethics"": ""Approved by METC-LDD, Netherlands; registered NCT05731999; informed consent obtained."", ""data_availability"": ""Clinical study data available at clinicaltrials.gov."", ""conflicts_of_interest"": ""Some authors are employees or patent holders related to Kontigo Care AB, the app developer.""}"
https://pmc.ncbi.nlm.nih.gov/articles/PMC8465466/,85a983ce-2881-4995-98ed-d46fe735af3b,85a983ce-2881-4995-98ed-d46fe735af3b.json,"This paper presents a deep learning-based method for detecting people with drug use disorders (PDUD) using facial images captured via standard RGB cameras. The study leverages a large dataset and transfer learning with a ResNet-18 CNN architecture to distinguish PDUD from the general population based on facial features. The model achieves high accuracy, sensitivity, and specificity, and is validated on external datasets simulating real-world clinical scenarios. The analysis also identifies specific facial regions (nose and cheeks) as being most indicative of drug use disorders. The approach is designed for rapid, non-invasive screening and could be integrated into clinical workflows or mobile applications.",A Method for Detecting and Analyzing Facial Features of People with Drug Use Disorders,2021,"Diagnostics (MDPI), https://doi.org/10.3390/diagnostics11091562",RGB,Facial Features,"general impairment, opioids, cannabis, stimulants, depressants, hallucinogens",Potential for real-time use; model designed for rapid screening and integration into clinical workflow or mobile apps,"9870 PDUD images, 19,567 general population images (training/test); 1677 PDUD and 50,000 GP images (external validation)","Clinical, primary care, emergency departments, mobile health app, internet-sourced videos/images","Accuracy (84.68% test, >83.69% external validation), Sensitivity (up to 87.93%), Specificity (up to 90.10%)",⭐⭐⭐,"Highly relevant: Uses standard RGB cameras for automated, real-time-capable visual detection of drug-related impairment, validated on large and diverse datasets, and provides quantitative analysis of facial features.","{""model_architecture"": ""ResNet-18 CNN with transfer learning and pre-trained on MS-Celeb-1M; attention mechanism explored but pre-training provided greater benefit."", ""feature_extraction"": ""Grad-CAM used for visualizing CNN attention; facial regions segmented (eyes, nose, cheeks, mouth) and quantitatively analyzed."", ""data_sources"": ""PDUD images/videos from a mobile health app (China), general population images/videos from the internet and public datasets."", ""preprocessing"": ""Face cropping, removal of occlusions, resizing to 224x224 pixels, data augmentation (color jitter, flipping, affine transforms)."", ""validation"": ""Seven external validation datasets constructed to simulate real-world prevalence and clinical scenarios."", ""statistical_analysis"": ""Chi-square tests used to compare feature distribution in facial regions between PDUD and general population."", ""deployment"": ""Model can be integrated into clinical workflows, mobile apps, or emergency department admission systems for rapid, non-invasive screening."", ""limitations"": ""No fine-grained categorization by drug type or duration of use; image quality may vary due to device hardware; non-visual methods not used."", ""ethics"": ""Ethics approval obtained; informed consent from all subjects."", ""funding"": ""Supported by National Natural Science Foundation of China and Beijing Advanced Discipline Construction Project.""}"
https://www.mdpi.com/2254-9625/12/9/99,18e28d3e-b36f-4b44-9db5-ddb80e21e878,18e28d3e-b36f-4b44-9db5-ddb80e21e878.json,"This study investigates emotion recognition abilities in individuals with alcohol and cocaine dependence using computer-based facial and body emotion recognition tasks, as well as a disgust rating task. The research uses visual stimuli (images of faces and bodies) to assess accuracy and reaction times in recognizing emotions. While the study provides insights into emotional processing deficits in substance abusers, it does not employ camera-based real-time detection or computer vision algorithms for intoxication detection, but rather uses pre-recorded images and manual response collection.",Decoding Emotion in Drug Abusers: Evidence for Face and Body Emotion Recognition and for Disgust Emotion,2022,"European Journal of Investigation in Health, Psychology and Education",RGB,Facial Features,"alcohol, cannabis, general impairment",No,"25 substance-dependent individuals (13 cocaine, 12 alcohol) and 33 controls",Controlled indoor laboratory/clinic setting,Accuracy and reaction time in emotion recognition tasks,⭐,"The study uses visual stimuli to assess emotional processing in substance abusers, but does not involve real-time camera-based detection or computer vision methods for intoxication/impairment detection. It relies on manual responses to pre-recorded images rather than automated or real-time analysis.","{""tasks"": [""Facial Emotion Recognition (FER) using Ekman and Friesen images (RGB photos of faces showing fear, sadness, happiness, anger)"", ""Body Emotion Recognition (BEAST) using BEAST dataset (RGB photos of body postures expressing emotions)"", ""Disgust Rating Task (DRT) using IAPS and internet images (various disgust categories: food, body products, animals, contamination, death, hygiene)""], ""metrics"": [""Percentage of correct answers (accuracy)"", ""Reaction time (ms)"", ""Inverse efficiency score (IES)""], ""findings"": {""emotion_recognition"": ""Substance-dependent individuals (alcohol, cocaine) were generally slower in recognizing emotions from faces and bodies compared to controls, but accuracy was not significantly different."", ""disgust_processing"": ""Alcohol-dependent subjects were slower in responding to disgusting food images."", ""gender_effects"": ""Cocaine-dependent females showed slower response times for certain emotions and disgust categories."", ""no_real_time"": ""All tasks were performed with pre-recorded images and manual keyboard responses; no real-time video or automated computer vision analysis was used.""}, ""limitations"": [""Small sample size"", ""No real-time or automated camera-based detection"", ""Manual response collection"", ""No use of computer vision algorithms""], ""ethics"": ""Approved by the Bioethics Committee of the Department of Brain and Behavioral Science of the University of Pavia; informed consent obtained.""}"
https://openaccess.thecvf.com/content/CVPR2024W/ABAW/papers/Dhake_Unravelling_Robustness_of_Deep_Face_Recognition_Networks_Against_Illicit_Drug_CVPRW_2024_paper.pdf,4132b73c-0592-4c57-9191-c45cbecf6430,4132b73c-0592-4c57-9191-c45cbecf6430.json,"This paper investigates the impact of illicit drug abuse on the robustness of deep face recognition networks using RGB images. It introduces a dataset of 'before' and 'after' drug abuse facial images, evaluates the performance drop in state-of-the-art face recognition and soft biometric (gender, ethnicity, expression) classifiers, and proposes CNN-based methods for detecting drug-altered faces. The study finds significant accuracy degradation in both identification and soft biometrics after drug abuse, and shows that simple image enhancement techniques are insufficient for mitigation. The work is highly relevant for real-time visual intoxication/impairment detection, especially in security and authentication contexts.",Unravelling Robustness of Deep Face Recognition Networks Against Illicit Drug Abuse Images,2024,CVPR Workshop / Computer Vision Foundation (Open Access),RGB,Facial Features,"general impairment, illicit drug abuse","Potential (methods are suitable for real-time, but not explicitly evaluated in real-time settings)","230 images (115 subjects, before and after drug abuse)","Unconstrained (in-the-wild, internet-sourced images)","Face identification accuracy (e.g., VGG-Face: 91.3% before, 73.9% after drug abuse); Soft biometrics accuracy; Drug abuse detection accuracy (DenseNet: 82%)",⭐⭐⭐,"Directly addresses visual detection of drug-induced impairment using camera-based facial analysis, evaluates both recognition and impairment detection, and proposes CNN-based solutions.","{""dataset"": {""name"": ""Drug Abuse Faces (DAF)"", ""composition"": ""115 subjects, each with 'before' (clean) and 'after' (post-drug) images"", ""privacy"": ""Faces blurred/eye strips for privacy""}, ""face recognition models evaluated"": [""VGG-Face"", ""ArcFace"", ""FaceNet"", ""OpenFace"", ""FaceNet512"", ""SFace"", ""DeepID""], ""performance_drop"": {""VGG-Face"": ""91.3% (before) → 73.9% (after)"", ""FaceNet"": ""84.3% (before) → 33.0% (after)""}, ""soft biometrics impact"": {""gender"": ""Accuracy drops from 83% (before) to 64% (after)"", ""ethnicity"": ""Significant drop in 'White' classification; some increases in other ethnicities"", ""expression"": ""Increase in sadness, anger, and disgust after drug abuse""}, ""image enhancement"": {""techniques"": [""Median blur"", ""Gaussian blur"", ""Morphological opening""], ""effectiveness"": ""Minimal improvement; Gaussian blur most effective but still limited""}, ""drug abuse detection"": {""traditional ML"": {""best_accuracy"": ""Decision Tree: 54%"", ""limitations"": ""Image pixels alone insufficient due to in-the-wild noise""}, ""CNN-based"": {""DenseNet"": ""82% accuracy, AUC-ROC 0.88"", ""VGG16+Random Forest"": ""78% accuracy""}}, ""social media filter robustness"": {""filters tested"": [""Inkwell"", ""Moon"", ""Xpro2"", ""Earlybird""], ""effect"": ""Significant further drop in recognition and detection accuracy for drug-altered faces""}, ""limitations"": [""Small dataset size"", ""No explicit real-time deployment or latency evaluation"", ""Focus on RGB only; no IR, NIR, or depth modalities""], ""future_work"": [""Expand dataset"", ""Develop advanced image enhancement for drug-induced alterations"", ""Explore synthetic data generation (e.g., diffusion models)""]}"
https://www.researchgate.net/publication/335341629_Face_Attributes_and_Detection_of_Drug_Addicts,b7e019a1-b694-45da-8e2b-7283172dd7da,b7e019a1-b694-45da-8e2b-7283172dd7da.json,"This paper presents a two-stage framework for detecting long-term drug abuse (specifically methamphetamine and heroin) using facial attributes extracted from RGB images. The approach first classifies five 'drug affect facial attributes' (blisters/acne, tissue muscle loss, hair loss, poor skin tone, gender) using deep CNNs (ResNet50, GoogleNet, VGG16) and SVM, then fuses these attributes in a Bayesian network for risk assessment. The best performance is achieved with ResNet50 and SVM for attribute detection (90% accuracy), and the full framework achieves 84% accuracy in classifying subjects as drug abusers or non-abusers. The study uses the Faces of Meth dataset and additional web images, and demonstrates that facial attribute-based reasoning outperforms direct CNN-based classification. The method is not real-time but is highly relevant for visual, camera-based impairment detection.",Face Attributes and Detection of Drug Addicts,2018,"Biometric Technologies Laboratory, University of Calgary",RGB,Facial Features,"opioids, general impairment","No (batch processing, not evaluated for real-time use)","112 images (Faces of Meth dataset) + 100 web images (44 abusers, 56 non-abusers)","Controlled (mugshots, web images; not real-world or in-the-wild)","Classification accuracy (84% overall, 89.29% non-abuser, 77.27% abuser)",⭐⭐⭐,"Highly relevant: exclusively uses camera-based (RGB) facial analysis for impairment detection, with a structured, explainable approach (facial attribute extraction + probabilistic reasoning). No non-visual modalities are used for detection.","{""attribute_list"": [""blisters/acne"", ""tissue muscle loss"", ""hair loss"", ""poor skin tone"", ""gender""], ""CNN_models"": [""ResNet50"", ""GoogleNet"", ""VGG16""], ""feature_selection_methods"": [""PCA"", ""Fisher's Linear Discriminant"", ""Lasso""], ""classifier"": ""Linear SVM (per attribute)"", ""Bayesian_network"": ""Used for risk assessment, fusing facial attribute evidence for final decision"", ""dataset_details"": {""Faces_of_Meth"": ""112 images (before/after drug abuse, mugshots)"", ""web_images"": ""44 abusers, 56 non-abusers""}, ""attribute_classification_accuracy"": {""ResNet50 (32 features, Fisher+PCA)"": {""blisters/acne"": ""86.61%"", ""tissue muscle loss"": ""88.39%"", ""gender"": ""93.75%"", ""hair loss"": ""91.96%"", ""poor skin tone"": ""89.29%""}}, ""final_framework_performance"": {""non-abuser_accuracy"": ""89.29%"", ""abuser_accuracy"": ""77.27%"", ""combined_accuracy"": ""84%"", ""sensitivity"": ""77.27%"", ""specificity"": ""89.29%"", ""precision"": ""85%""}, ""direct_CNN_baseline"": {""non-abuser_accuracy"": ""70.54%"", ""abuser_accuracy"": ""65.18%"", ""combined_accuracy"": ""67.86%""}, ""limitations"": [""Not real-time; batch processing only"", ""Small dataset size"", ""Controlled image conditions (mugshots, not in-the-wild)"", ""Only detects long-term (0.5–3 years) drug abuse, not acute intoxication""], ""future_work"": [""Larger datasets or synthetic data (GANs)"", ""Real-time implementation"", ""Inclusion of behavioral biometrics (body, gait, gestures)""]}"
https://www.engineeringletters.com/issues_v31/issue_3/EL_31_3_23.pdf,ddcfbd47-85dd-4c86-ab2a-87123464fbf2,ddcfbd47-85dd-4c86-ab2a-87123464fbf2.json,"This paper presents a deep learning-based framework using CCTV face images to classify drug users versus non-users. The system employs face detection, data augmentation, and transfer learning with GoogLeNet, achieving 87.14% accuracy on a diverse dataset. The approach focuses on long-term facial changes due to drug abuse, such as wrinkles and loss of elasticity, and is evaluated in a simulated CCTV environment. The method is not real-time but is relevant for visual drug user identification in surveillance footage.",Facial Feature Classification of Drug Addicts Using Deep Learning,2023,"Engineering Letters, Volume 31, Issue 3, September 2023",RGB,Facial Features,general impairment,"No (batch processing of images, not real-time)","2,100 original images (1,050 drug users, 1,050 non-users), augmented to 70,560 images","Simulated CCTV (images from Internet, police agencies, and public face datasets)","Accuracy (87.14%), F1-score (87.32%)",⭐⭐,"Directly addresses visual detection of drug-related impairment using facial features in CCTV images, but focuses on long-term facial changes rather than acute intoxication and is not real-time.","{""deep_learning_model"": ""GoogLeNet with transfer learning; compared with AlexNet, VGGNet, ResNet, Inception, Xception, DenseNet, MobileNet, ShuffleNet"", ""face_detection_method"": ""Viola-Jones (Haar cascade)"", ""data_augmentation"": [""horizontal/vertical flip"", ""translation"", ""rotation"", ""scaling"", ""brightness adjustment"", ""blur"", ""shearing""], ""dataset_sources"": [""Internet (Western faces)"", ""Police agency (Eastern faces)"", ""VGGFace2"", ""CAFR"", ""MORPH Album 2""], ""classification_task"": ""Binary classification: drug user vs. non-user"", ""validation_method"": ""Hold-out (70% training, 30% testing)"", ""activation_functions_tested"": [""ReLU (best)"", ""Leaky ReLU"", ""ELU"", ""Clipped ReLU""], ""dropout_optimization"": ""Best accuracy at dropout probability 0.45"", ""limitations"": [""Not real-time"", ""Focuses on chronic/long-term facial changes, not acute intoxication"", ""RGB only; no IR, NIR, thermal, or depth modalities"", ""Potential confounds from non-drug-related facial conditions""], ""future_work"": ""Plan to fuse facial blob features for improved accuracy""}"
https://pmc.ncbi.nlm.nih.gov/articles/PMC4905685/,e9fee161-f5ad-4a8d-978a-94a0c13557f4,e9fee161-f5ad-4a8d-978a-94a0c13557f4.json,"This review paper synthesizes evidence that psychoactive drugs (alcohol, nicotine, cannabinoids, opioids, stimulants) acutely and chronically alter the perception and processing of emotional facial expressions in humans. The reviewed studies primarily use behavioral tasks and neuroimaging to assess changes in recognition of emotions from faces under drug influence. While the findings are highly relevant for understanding drug-induced social and emotional impairment, the paper does not focus on or develop real-time, camera-based computer vision methods for intoxication detection.",Drug effects on responses to emotional facial expressions: recent findings,2015,Behav Pharmacol. 2015 September ; 26(6): 571–579. doi:10.1097/FBP.0000000000000164.,No Camera,Facial Features,"alcohol, cannabis, opioids, stimulants, nicotine",No,Review (varies by referenced study),Laboratory and naturalistic (varies by referenced study),Not applicable (review paper),⭐,"The paper reviews behavioral and neuroimaging studies on drug effects on facial emotion processing, which is conceptually relevant to visual intoxication detection. However, it does not present or evaluate any camera-based, real-time, or computer vision methods for intoxication detection.","{""drugs_reviewed"": [""alcohol"", ""nicotine"", ""cannabinoids (THC, CBD)"", ""opioids (heroin, buprenorphine, oxycodone, morphine)"", ""stimulants (amphetamine, MDMA, methamphetamine, cocaine)""], ""main_findings"": {""alcohol"": ""Acute use increases perceived attractiveness and reduces sensitivity to negative emotions; chronic use impairs recognition of negative emotions."", ""nicotine"": ""Acute use increases ratings of facial attractiveness; little is known about effects on specific emotion recognition."", ""cannabinoids"": ""THC and CBD reduce recognition and neural response to threatening faces (anger, fear); chronic use slows emotion identification."", ""opioids"": ""Acute use reduces recognition of fearful faces and neural response to negative emotions; chronic use slows overall emotion recognition."", ""stimulants"": ""MDMA enhances recognition of positive emotions and dampens response to negative ones; other stimulants may increase speed of emotion identification.""}, ""methods_in_referenced_studies"": [""Behavioral tasks (emotion recognition from facial images)"", ""Functional MRI (neural response to emotional faces)"", ""Facial electromyography""], ""limitations"": [""No use of camera-based or computer vision systems for intoxication detection."", ""Focus is on psychological and neural mechanisms, not on automated or real-time detection."", ""Non-visual methods (subjective, physiological) are included in referenced studies.""], ""future_directions"": [""Need for longitudinal studies to determine causality between drug use and emotion processing deficits."", ""Potential for individual differences (sex, genetics, personality) to moderate drug effects on facial processing.""]}"
https://hal.science/hal-03489500v1/file/S0010482519303452.pdf,02079137-d406-4398-84d7-a4d1aeaf2ed7,02079137-d406-4398-84d7-a4d1aeaf2ed7.json,"This paper investigates the impact of methamphetamine abuse on facial asymmetry using 2D RGB images. The study introduces automated metrics for both geometrical and textural facial asymmetry, applying them to a database of meth addicts and a control group from the FERET aging database. Results show a significant increase in facial asymmetry among meth users compared to normal aging, with implications for biometric systems and potential real-time visual detection of long-term drug abuse effects. The work is highly relevant for visual-based impairment detection, though it focuses on long-term, not acute, intoxication.",Methamphetamine Drug Abuse and Addiction: Effects on Face Asymmetry,2020,"Computers in Biology and Medicine, Elsevier; HAL open archive: hal-03489500",RGB,Facial Features,general impairment,"No (offline analysis, but methods could be adapted for real-time use)","120 meth-addicted subjects (2 images each), 80 control subjects (FERET database)","Uncontrolled (internet photo collections, mugshots, FERET database)",Statistical increase in facial asymmetry (geometrical and textural indices),⭐⭐,"The study uses visual features from RGB images to detect long-term impairment (methamphetamine abuse) via facial asymmetry. While not real-time or focused on acute intoxication, the methods and findings are directly relevant to camera-based impairment detection and could inform real-time systems.","{""databases_used"": [""Illicit Drug Addicts database (120 subjects, 2+ frontal color images each, collected from internet and 'faces of meth' project)"", ""FERET database (80 subjects, 2+ frontal color images each, for normal aging control)""], ""facial asymmetry metrics"": {""geometrical"": [""Bilateral features (local, based on Dlib 68 facial landmarks)"", ""Area Mismatch metric (global, automated from landmarks, inspired by SymNose software)""], ""textural"": [""Structural Similarity Index (SSIM) between dual face regions (cheeks, eyes, mouth)""]}, ""preprocessing"": [""Face detection and landmark extraction (Dlib, iBUG 300-W trained)"", ""Affine transformation for alignment"", ""Face cropping and ROI extraction""], ""statistical findings"": {""meth-addicts"": {""geometrical asymmetry increase"": ""5% (mean)"", ""textural asymmetry increase"": ""11% (mean)""}, ""normal aging"": {""geometrical asymmetry increase"": ""1% (mean)"", ""textural asymmetry increase"": ""3% (mean)""}}, ""limitations"": [""Focuses on long-term effects, not acute intoxication"", ""Uncontrolled image sources (mugshots, internet photos)"", ""No real-time implementation, but methods are automatable"", ""Landmark detection limited by current technology (Dlib 68 points)""], ""potential for real-time adaptation"": ""Automated landmark detection and asymmetry metrics could be implemented in real-time systems for visual impairment screening."", ""3D extension"": ""Discussion and toy example of extending asymmetry metrics to 3D face meshes using single-image 3D reconstruction, but not evaluated on real 3D data.""}"
https://ieeexplore.ieee.org/document/7477556,3692345a-d6af-41e3-b1c9-e9ce1defbf0f,3692345a-d6af-41e3-b1c9-e9ce1defbf0f.json,"This paper investigates the impact of illicit drug abuse on facial features and the performance of face recognition systems. The authors introduce the Illicit Drug Abuse Face (IDAF) dataset, containing before-and-after images of 105 subjects with a history of drug abuse. They demonstrate that current face recognition algorithms suffer significant performance drops when processing faces affected by drug abuse. To address this, the paper proposes a real-time, dictionary learning-based classification framework (DDAC) that detects and separates drug-affected faces from regular ones, achieving an accuracy of 88.81%. The approach is non-invasive, uses only RGB images, and focuses on textural and structural facial changes.",Effect of Illicit Drug Abuse on Face Recognition,2016,CVPR Workshops,RGB,Facial Features,"general impairment, cannabis, cocaine, methamphetamine, heroin",Yes (classification time ~0.59s per image; suitable for real-time use),"105 subjects (IDAF dataset), 210 images (before/after), plus 1000 subjects in combined experiments","Images collected from the internet (rehab/mugshot sources); controlled datasets (CMU Multi-PIE, CASIA-VIS-NIR) for regular faces",Classification accuracy (88.81% for DDAC framework),⭐⭐⭐,"The paper directly addresses visual detection of drug-induced impairment using RGB facial images, proposes a real-time-capable algorithm, and provides a public dataset. It is highly relevant for camera-based intoxication/impairment detection.","{""dataset"": {""name"": ""Illicit Drug Abuse Face (IDAF)"", ""size"": ""105 subjects, 210 images (before/after drug abuse)"", ""substances"": [""methamphetamine"", ""cocaine"", ""heroin"", ""crack""], ""availability"": ""To be released to the research community""}, ""face_recognition_algorithms_tested"": [""FaceVACS (COTS)"", ""Luxand (COTS)"", ""LBP"", ""HOG""], ""proposed_method"": {""name"": ""Dictionary learning based illicit Drug Abuse face Classification (DDAC)"", ""features_used"": [""multi-scale Binarized Statistical Image Features (BSIF)"", ""GIST descriptor""], ""ROIs"": [""full face"", ""binocular region"", ""right cheek"", ""left cheek"", ""forehead""], ""fusion"": ""Decision-level fusion (logical OR) of BSIF and GIST dictionary outputs""}, ""performance"": {""DDAC_accuracy"": ""88.81%"", ""true_positive_rate"": ""80.95%"", ""true_negative_rate"": ""92.06%"", ""comparison"": {""multi-scale BSIF + SVM"": ""75.00%"", ""HOG + SVM"": ""76.90%"", ""Self-Similarity + SVM"": ""78.01%"", ""GIST + SVM"": ""81.09%"", ""LBP + SVM"": ""81.41%""}}, ""computational_time"": ""0.59 seconds per image (feature extraction + classification) on desktop PC (3.4 GHz CPU, 16 GB RAM)"", ""limitations"": [""Only RGB images used; no IR/NIR, thermal, or depth modalities"", ""Images sourced from the internet may have uncontrolled conditions"", ""Focus is on long-term facial changes, not acute intoxication""]}"
https://www.mdpi.com/2078-2489/16/5/413,84aaa525-04cb-416f-9a29-24400a48a3d6,84aaa525-04cb-416f-9a29-24400a48a3d6.json,"This paper presents a machine learning-based approach for detecting alcohol intoxication using thermal facial images. The study utilizes both self-collected and public datasets, extracting facial thermal patterns with YOLO and FaceMesh, and classifies intoxication states using several machine learning models. The best-performing model (MLP) achieved 90% accuracy in distinguishing between sober and drunk individuals. The work demonstrates the feasibility of real-time, camera-based drunk driver detection using thermal imaging, though it is currently validated only in controlled environments.",Drunk Driver Detection Using Thermal Facial Images,2025,"Information 2025, 16, 413. https://doi.org/10.3390/info16050413",Thermal,Facial Thermal Imaging,alcohol,"Potential for real-time; models (YOLO, FaceMesh, MLP) are suitable for real-time deployment but only tested in controlled/lab settings","20 participants (self-collected, 240 images), augmented to 570 images; plus 1315 images from Tufts Face dataset","Controlled indoor (air-conditioned, 25-30°C), no direct sunlight or external heat sources",Accuracy (MLP: 90%),⭐⭐⭐,Directly addresses real-time visual intoxication detection using thermal cameras and facial analysis; uses modern deep learning and facial landmarking; validated on relevant datasets.,"{""datasets"": [""Self-collected thermal facial images (20 participants, 240 images, multiple angles, sober and post-alcohol)"", ""Tufts Face Database (thermal and RGB images, 1315 images used for training/augmentation)""], ""hardware"": ""FLIR T530 Professional Thermal Camera (NETD < 40 mK, ±2°C accuracy); Intel i5-9300H CPU, NVIDIA GTX 1650 GPU, 16GB RAM"", ""feature_extraction"": [""YOLOv8 for face detection and region annotation"", ""FaceMesh (MediaPipe) for 468 3D facial landmarks; 22 grid points used for classification""], ""classification_models"": [""Support Vector Machine (SVM)"", ""Multi-Layer Perceptron (MLP)"", ""Random Forest (RF)"", ""Logistic Regression (LR)"", ""K-Nearest Neighbors (KNN)""], ""best_model"": ""MLP (3 dense layers, ReLU, batch normalization, dropout, Adam optimizer, binary cross-entropy loss)"", ""performance_metrics"": {""MLP"": {""accuracy"": ""90%"", ""precision"": ""Sober: 86%, Drunk: 93%"", ""recall"": ""Sober: 91%, Drunk: 89%"", ""F1"": ""Sober: 89%, Drunk: 91%""}, ""KNN"": {""accuracy"": ""88%""}, ""RF"": {""accuracy"": ""89%""}, ""SVM"": {""accuracy"": ""75%""}, ""LR"": {""accuracy"": ""78%""}}, ""data_augmentation"": ""Initial 240 images augmented to 570; additional images from Tufts Face dataset for diversity"", ""validation"": ""75-25% train-test split; cross-dataset validation; repeated training with 101 random seeds"", ""limitations"": [""Tested only in controlled, indoor, tropical environment"", ""Sample size is small and demographically homogeneous (young adults, 21-25 years)"", ""No validation in real driving or in-vehicle scenarios"", ""Performance with facial obstructions (beards, mustaches) not evaluated"", ""Thermal camera dependency; results may vary with different hardware""], ""potential_applications"": [""In-vehicle real-time drunk driver detection systems"", ""Advanced driver assistance systems (ADAS)""], ""future_work"": [""Validation in diverse climates and real-world driving conditions"", ""Testing with broader demographics and facial variations"", ""Robustness to environmental and facial occlusion factors""]}"
https://www.mdpi.com/2079-9292/11/23/3924,88940355-4a96-4d2b-be57-aeed60d30e56,88940355-4a96-4d2b-be57-aeed60d30e56.json,"This paper presents a non-invasive, real-time method for identifying alcohol intoxication using multi-frame thermal facial imagery. By analyzing isothermal regions of the face, particularly the forehead, and extracting morphological features, the method achieves high accuracy in distinguishing drunk from sober individuals. The approach does not require a baseline (sober) image for comparison, making it suitable for real-world applications such as roadside screening.",Thermal Biometric Features for Drunk Person Identification Using Multi-Frame Imagery,2022,"Electronics (MDPI), https://doi.org/10.3390/electronics11233924",Thermal,Facial Thermal Imaging,alcohol,"Yes (fast, non-invasive, multi-frame analysis)","41 participants, 4100 thermal images (50 frames per person, sober and drunk)","Controlled indoor environment (23-25°C, dim light, 30 cm camera distance)","Success rate (identification accuracy), up to 86%",⭐⭐⭐,"Highly relevant: Uses thermal camera for real-time, non-contact alcohol intoxication detection with robust accuracy and no need for baseline images.","{""database"": ""Publicly available thermal face database (http://old.physics.upatras.gr/sober/)"", ""camera_specs"": ""Thermal Vision Micron/A10, 160x128 pixels, 7.5–13.0 µm sensitivity"", ""feature_extraction"": [""Isothermal region segmentation (histogram-based, forehead isolation)"", ""Anisotropic diffusion for noise reduction"", ""Morphological operations (openings, pattern spectrum/pecstrum)""], ""classification"": ""Support Vector Machine (SVM) with various kernels (linear, precomputed, polynomial, RBF, sigmoidal)"", ""best_results"": ""Forehead isothermal isolation + pattern spectrum (no diffusion) + linear/precomputed SVM: 86% accuracy"", ""multi-frame approach"": ""50 frames per subject per condition, enabling robust feature vector clusters"", ""limitations"": [""Only healthy, calm subjects (no illness, stress, or exercise)"", ""Controlled environment; real-world variability not fully tested"", ""No direct blood alcohol measurement for all subjects (breathalyzer used for subset)""], ""novelty"": [""No need for a sober baseline image for each subject"", ""First use of isothermal forehead isolation as a unique intoxication marker""], ""ethics"": ""Approved by University of Patras Bioethics Committee; informed consent obtained""}"
https://ieeexplore.ieee.org/document/8538761,a92e3d39-43ce-4e43-a72b-ca3b5cdcdba4,a92e3d39-43ce-4e43-a72b-ca3b5cdcdba4.json,"This paper presents a multi-modal approach for intoxicated person identification using thermal infrared imaging and gait analysis. The method leverages facial blood vessel activity, temperature distribution in the eye region, and walking patterns to distinguish between sober and intoxicated individuals. Feature extraction is performed using Curvelet Transform for facial vessels, SURF for eye temperature differences, and optical flow for gait analysis. Classification is achieved using Random Forest and SVM. The study demonstrates high accuracy, especially for eye and gait features, and is validated on a dataset of 40 participants under controlled conditions.",Intoxicated Person Identification Using Thermal Infrared Images and Gait,2018,IEEE Conference Paper,Thermal,Facial Thermal Imaging,alcohol,"Potential (frame-based processing, but not explicitly real-time; methods are computationally efficient)","40 participants (30 males, 10 females); 1850 images per class for face/eye; 4 subjects for gait",Controlled indoor environment with stable temperature and dim lighting; 30 cm face-camera distance,"Classification accuracy (Face: 89.23%, Eye: 100%, Gait: ~100%)",⭐⭐⭐,"Highly relevant: Uses only thermal camera data for intoxication detection, covers multiple visual features (face, eyes, gait), and demonstrates high accuracy. Methods are suitable for real-time or near real-time application.","{""feature_extraction_methods"": {""face"": ""Curvelet Transform to highlight facial blood vessels"", ""eye"": ""SURF (Speeded Up Robust Features) to capture temperature differences between iris and sclera"", ""gait"": ""Optical flow to analyze walking trajectory and body sway""}, ""classification_methods"": [""Random Forest (face features)"", ""SVM (eye and gait features)""], ""dataset_details"": {""thermal_camera"": ""Thermal Vision Micron/A10 infrared camera (7000–13,000 nm, 128x160 px)"", ""alcohol_protocol"": ""4 glasses of wine (62.4 mL alcohol) per participant; images acquired before and 30 min after consumption"", ""gait_data"": ""4 students, 240-frame video, sober and simulated drunk walking""}, ""fusion_strategy"": ""Logical OR: If two out of three tests (face, eye, gait) indicate intoxication, the person is classified as drunk"", ""limitations"": [""No blood tests for BAC; intoxication defined by amount consumed and breathalyzer"", ""Gait dataset is small (4 subjects, simulated drunk walking)"", ""Hand and ear thermal images collected but not found useful for intoxication detection""], ""notable_results"": {""face_thermal_accuracy"": ""89.23% (drunk), 91.85% (sober)"", ""eye_thermal_accuracy"": ""100% (both classes)"", ""gait_accuracy"": ""100% (both classes, small dataset)""}, ""public_availability"": ""Hand and ear thermal image database is publicly available""}"
https://www.researchgate.net/publication/326219591_Intoxication_Identification_Using_Thermal_Imaging,27b1731a-f91d-45fc-9e97-f542a7ec2990,27b1731a-f91d-45fc-9e97-f542a7ec2990.json,"This chapter presents seven distinct thermal imaging-based methods for identifying alcohol intoxication by analyzing facial thermal signatures. The approaches leverage features such as temperature differences across facial regions, blood vessel activity, isothermal region analysis, and neural network-based classification, all using non-contact thermal infrared cameras. The study is based on a systematically collected database of 41 participants, with both sober and intoxicated states recorded. Most methods do not require a baseline (sober) image for comparison, making them suitable for real-time, practical deployment. Reported identification accuracies exceed 80%, with some methods achieving up to 90%. The work is highly relevant for noninvasive, real-time intoxication detection using visual (thermal) modalities.",Intoxication Identification Using Thermal Imaging,2018,"IntechOpen, Chapter 8 in 'Human-Robot Interaction - Theory and Application'",Thermal,Facial Thermal Imaging,alcohol,"Yes (methods designed for real-time, non-contact screening; most do not require a baseline image)","41 participants (10 females), each imaged sober and after alcohol consumption","Controlled indoor laboratory; participants at rest, no exercise, standardized alcohol dose (half liter wine per subject)","Identification success rate (>80% for all methods, up to 90% for some neural network/forehead-based approaches)",⭐⭐⭐,"This work is highly relevant as it systematically explores multiple real-time, camera-based (thermal) methods for alcohol intoxication detection, with robust experimental validation and a public dataset. The methods are noninvasive, do not require a baseline image, and are suitable for practical deployment.","{""database"": ""Freely available thermal face image database (sober and intoxicated states) from University of Patras, Greece (http://www.physics.upatras.gr/sober/)"", ""thermal_camera"": ""Thermo Vision Micron A10, 7.5–13 μm wavelength, 128x160 pixel resolution, 10 fps"", ""feature extraction methods"": [""20-point facial temperature vector and Fisher Linear Discriminant analysis"", ""Temperature difference matrices across 8x5 facial regions"", ""Morphological analysis (top-hat transformation) for blood vessel activity"", ""Neural networks (various architectures) for pixel/region-based classification"", ""Eye-region analysis (sclera vs. iris temperature difference)"", ""Isothermal region segmentation and pattern spectrum analysis with SVMs"", ""Markov chain modeling of forehead pixel transitions and eigenvalue-based classification""], ""key findings"": [""Nose and mouth regions become hotter relative to forehead after alcohol consumption"", ""Blood vessel activity (as seen in thermal images) increases with intoxication"", ""Sclera temperature increases relative to iris in intoxicated subjects"", ""Isothermal region area and distribution change with intoxication, especially on the forehead"", ""Most methods achieve >80% accuracy; neural network and Markov chain approaches on the forehead reach ~90%"", ""Majority of methods do not require a baseline (sober) image for comparison""], ""limitations"": [""No blood tests were performed; intoxication was inferred from standardized alcohol dose and breathalyzer readings"", ""Study limited to alcohol; other substances not addressed"", ""Controlled environment; real-world variability (lighting, movement, other impairments) not fully explored""], ""future_work"": ""Fusion of multiple feature types for improved accuracy; real-world deployment and validation; extension to other types of impairment.""}"
https://pubmed.ncbi.nlm.nih.gov/27404407/,a4ed8c79-868a-48d2-b7f4-7768a32e76b2,a4ed8c79-868a-48d2-b7f4-7768a32e76b2.json,"This paper investigates the use of thermal infrared imaging to detect alcohol intoxication by analyzing temperature differences between the sclera and iris in the human eye. The study involved 41 participants who consumed alcohol in a controlled setting, with thermal images captured before and after drinking. The results show that, for most intoxicated individuals, the sclera becomes significantly hotter than the iris, a feature that can be statistically verified and used for drunk screening. The method demonstrates high discrimination capability and suggests potential for real-time, noninvasive intoxication detection using thermal cameras.",Drunk Person Screening using Eye Thermal Signatures,2016,Journal of Forensic Sciences,Thermal,Facial Thermal Imaging,alcohol,"Potential (not explicitly real-time, but method is suitable for real-time implementation)","41 participants (31 males, 10 females)",Controlled indoor environment with stable temperature and dim lighting,"Statistical discrimination (Student's t-test, >99% confidence in discrimination between sober and drunk states)",⭐⭐⭐,"Directly addresses camera-based (thermal) intoxication detection with a clear, statistically validated visual biomarker; method is suitable for real-time screening.","{""thermal_camera_model"": ""FLIR Thermo Vision Micron/A10 (7.5–13.0 μm range, 128x160 pixels)"", ""alcohol_dose"": ""480 mL red wine (62.4 mL alcohol, 13% vol) per participant"", ""acquisition_protocol"": ""50 frames per person before and after alcohol consumption, 100 ms interval between frames"", ""feature_extraction"": [""Ratio of mean pixel value (sclera/iris)"", ""Variance of pixel values in eye region""], ""statistical_analysis"": [""Welch's t-test"", ""Paired t-test""], ""results"": {""sclera_hotter_in_drunk"": ""36/41 participants"", ""preprocessing_needed"": ""In 8/41 cases, histogram modification or contrast stretching required to reveal difference"", ""no_effect"": ""5/41 participants (frequent drinkers or low BrAC)""}, ""limitations"": [""Not all individuals show the effect (especially frequent drinkers or those with low BrAC)"", ""Requires close-up thermal imaging of the eyes"", ""Not tested in unconstrained or outdoor environments""], ""ethics"": ""Approved by University of Patras Bioethics Committee"", ""data_availability"": ""Database available at www.physics.upatras.gr/sober/"", ""forensic_application"": ""Potential for use by authorities as a noninvasive screening tool""}"
https://pubmed.ncbi.nlm.nih.gov/3387346/,a332c172-57c4-458f-b124-65deaa7ed45d,a332c172-57c4-458f-b124-65deaa7ed45d.json,"This 1988 paper introduces the 'rapid eye test' as a clinical and field method for detecting acute drug intoxication based on visual examination of eye signs. The test assesses features such as pupil size, reactivity, nystagmus, ptosis, and convergence, which are affected by various drugs including alcohol, cannabis, opioids, stimulants, and PCP. The method is noninvasive, quick, and can be administered by trained nonmedical personnel, making it suitable for real-time screening in diverse environments. However, the test is subjective, relies on human observation, and is not automated or camera-based, limiting its direct relevance to computer vision applications.",The rapid eye test to detect drug abuse,1988,"Postgraduate Medicine, 84:1, 108-114, DOI: 10.1080/00325481.1988.11700339",No Camera,Eye,"alcohol, cannabis, opioids, general impairment, mixed","Yes (manual, not automated)",Not specified; based on clinical experience and literature review,"Clinical, law enforcement, workplace, sports, schools",Not quantitatively reported; described as reliable with few false positives,⭐,The paper is foundational for visual intoxication detection but does not use camera-based or automated computer vision methods. It is relevant for feature selection and understanding visual signs but not for real-time camera-based systems.,"{""test_components"": [""General observation (redness, ptosis, eyelid retraction, glazing, tearing, swelling)"", ""Pupil size (dilation, constriction)"", ""Pupil reaction to light (sluggish, absent)"", ""Nystagmus (horizontal, vertical, rotational)"", ""Convergence (failure to converge, inability to hold cross-eyed position)"", ""Corneal reflex (decreased blinking)""], ""drug_specific_eye_signs"": {""marijuana"": [""normal-sized pupil"", ""slow/no reaction to light"", ""nonconvergence"", ""redness"", ""glazing"", ""horizontal nystagmus"", ""swollen eyelids"", ""watering""], ""heroin"": [""constricted pupil"", ""nonreactive pupil"", ""ptosis"", ""glazing"", ""decreased corneal reflex"", ""swollen eyelids""], ""alcohol/benzodiazepines"": [""normal-sized pupil"", ""slow/no reaction to light"", ""nystagmus"", ""redness"", ""glazing"", ""nonconvergence""], ""cocaine/amphetamine"": [""dilated pupil"", ""slow/no reaction to light"", ""decreased corneal reflex""], ""PCP"": [""normal-sized pupil"", ""slow/no reaction to light"", ""nystagmus"", ""retracted upper eyelid"", ""decreased corneal reflex"", ""swollen eyelids""]}, ""criteria_for_positive_test"": ""Two or more of five primary eye signs (ptosis, abnormal pupil size, nonreactive pupil, nystagmus, nonconvergence) must be present."", ""limitations"": [""Subjective, requires trained human observer"", ""Not automated or camera-based"", ""False positives possible due to congenital or neurological conditions"", ""Does not detect past drug use if not acutely intoxicated"", ""Confirmation by body fluid analysis recommended""], ""use_cases"": [""Screening in clinical, workplace, sports, and law enforcement settings"", ""Fitness-for-duty assessments""], ""historical_context"": ""Test formalized in the 1970s, widely used by law enforcement and clinicians by the 1980s."", ""non-visual_methods_mentioned"": ""Urine and blood testing for confirmation (not relevant to computer vision).""}"
https://www.sciencedirect.com/science/article/pii/S1752928X23000203,2f683c34-534d-40fb-803f-3620961d4cc8,2f683c34-534d-40fb-803f-3620961d4cc8.json,"This study investigated whether nystagmus, as assessed by a clinical test of impairment (CTI), is associated with amphetamine use in apprehended drivers. Using a large sample of real-world DUI cases, the authors found that nystagmus was not more prevalent in amphetamine-only cases than in drug-negative controls, and there was no association between blood amphetamine concentration and degree of nystagmus. The findings suggest that nystagmus is not a reliable visual indicator of amphetamine-induced impairment, in contrast to its established association with alcohol intoxication.",Nystagmus among suspected amphetamine impaired drivers,2023,Journal of Forensic and Legal Medicine 95 (2023) 102502,No Camera,Eye,amphetamines,"No (clinical/physician-administered test, not camera-based)","507 amphetamine-only cases, 485 alcohol-only cases, 205 drug-negative cases","Naturalistic (apprehended drivers, roadside/forensic setting)","Proportion of cases with nystagmus; statistical association (Chi-square, Spearman’s correlation)",⭐,"The study focuses on a visual feature (nystagmus) relevant to impairment detection, but does not use camera-based or automated computer vision methods. Results are only applicable to clinical/physician-administered tests, not real-time camera-based systems.","{""nystagmus_assessment"": ""Horizontal gaze nystagmus was scored as 'no', 'slight', or 'obvious' by a physician as part of a 25-item clinical test of impairment (CTI)."", ""statistical_results"": {""amphetamine_only_nystagmus"": ""21%"", ""alcohol_only_nystagmus"": ""53%"", ""drug_negative_nystagmus"": ""25%"", ""p_value_amphetamine_vs_control"": ""0.273"", ""p_value_alcohol_vs_others"": ""<0.001"", ""correlation_amphetamine_concentration_nystagmus"": ""Spearman’s ρ = 0.008, p = 0.860"", ""correlation_alcohol_concentration_nystagmus"": ""Spearman’s ρ = 0.249, p < 0.001""}, ""sample_demographics"": {""amphetamine_only"": {""n"": 507, ""median_age"": 39, ""age_range"": ""17–71"", ""male_percentage"": 85, ""median_concentration"": ""0.37 mg/L""}, ""alcohol_only"": {""n"": 485, ""median_age"": 35, ""age_range"": ""16–80"", ""male_percentage"": 80, ""median_concentration"": ""1.57 g/kg""}, ""drug_negative"": {""n"": 205, ""median_age"": 31, ""age_range"": ""16–72"", ""male_percentage"": 91}}, ""limitations"": [""No camera-based or automated visual assessment; all nystagmus scoring was manual by physicians."", ""Timing of amphetamine intake relative to testing was unknown."", ""Results do not generalize to real-time or automated vision-based systems.""], ""conclusion"": ""Nystagmus is not a reliable indicator of amphetamine-induced impairment and should not be used as a tool for identifying amphetamine impairment in drivers.""}"
https://www.nature.com/articles/s41598-023-39104-7,1c957742-7f54-445f-9963-6a9f95075f55,1c957742-7f54-445f-9963-6a9f95075f55.json,"This paper presents ANyEye, a deep learning-based system for automated extraction of nystagmus from video-nystagmography (VNG) infrared videos, primarily for diagnosing benign paroxysmal positional vertigo (BPPV). The system uses a CNN for pupil segmentation and a compensation algorithm for accurate pupil tracking, along with a moving-average-based algorithm to detect and remove motion artifacts caused by goggle slippage. The method achieves high accuracy in pupil tracking and is evaluated on real patient data. While the focus is on vestibular disorders, the visual techniques and real-time tracking are highly relevant to camera-based impairment detection, especially for eye-movement analysis.",A nystagmus extraction system using artificial intelligence for video‑nystagmography,2023,"Scientific Reports (Nature), https://doi.org/10.1038/s41598-023-39104-7",IR/NIR,Eye,general impairment,Yes (real-time or near real-time inference demonstrated),"Video data from 48 posterior and 4 lateral semicircular canal BPPV patients (66 tests, 165 video clips, 8434 frames for segmentation, 8 videos for slippage detection)","Clinical/hospital setting using video-nystagmography goggles (IR camera, 640x480 px, 30 fps)","Five-pixel error detection rate (91.26%), Dice coefficient, AUROC",⭐⭐⭐,"Highly relevant: The paper demonstrates robust, real-time visual tracking of eye-movement and pupil dynamics using IR video, with direct application to impairment detection via nystagmus analysis. The methods and evaluation are directly transferable to intoxication/impairment detection scenarios.","{""system_name"": ""ANyEye"", ""deep_learning_model"": ""CNN-based segmentation (U-Net and U-Net++ variants)"", ""compensation_algorithm"": ""Ellipse fitting and temporal consistency checks for robust pupil center estimation"", ""slippage_detection"": ""Two-stage moving average (short and long window) to remove motion artifacts from goggle slippage"", ""data_labeling"": ""Manual annotation of pupil boundaries by four researchers using a custom tool; ground truth generated via RANSAC ellipse fitting"", ""training_details"": {""input_size"": ""256x256 px"", ""augmentation"": ""Random rotation, scaling, and shift"", ""optimizer"": ""Adam, learning rate 0.001, 500 epochs, early stopping"", ""framework"": ""PyTorch""}, ""test_set_evaluation"": {""detection_rate_at_5px"": ""91.26% (ANyEye), outperforming EllSeg, PuRe, ElSe, ExCuSe"", ""mean_detection_error"": ""2.05 ± 2.01 pixels""}, ""limitations"": [""Only one VNG device used; generalization to other devices not validated"", ""Short-length motion artifacts may not be fully removed"", ""Not validated with external datasets"", ""Not directly focused on intoxication, but on vestibular impairment (BPPV)""], ""future_work"": [""External validation"", ""Extension to automated BPPV type classification"", ""Improved noise/artifact handling""], ""data_availability"": ""Not publicly available due to patient privacy; available on request""}"
https://pmc.ncbi.nlm.nih.gov/articles/PMC11884307/,5cc21596-c2bb-4a78-8ce4-41464862d6cf,5cc21596-c2bb-4a78-8ce4-41464862d6cf.json,"This case report demonstrates the use of a low-cost, commercially available mini-infrared camera integrated with 3D-printed goggles for at-home, real-time monitoring of nystagmus in a patient with episodic vertigo. The system enabled successful recording of eye movements during vertigo attacks in dark conditions, leading to an accurate diagnosis of BPPV that was not possible during standard outpatient visits. The approach highlights the feasibility and utility of accessible, camera-based visual monitoring for vestibular disorder diagnosis, with strong implications for telemedicine and remote care.",Monitoring Nystagmus in a Patient With Vertigo Using a Commercial Mini-Infrared Camera and 3D Printer: Cost-Effectiveness Evaluation and Case Report,2025,JMIR Formative Research,IR/NIR,Eye,general impairment,"Yes (at-home, during episodes)",1 (case report),"Home (dark conditions), telemedicine context",Qualitative diagnostic confirmation (nystagmus detection and BPPV diagnosis),⭐⭐,"The study directly demonstrates real-time, camera-based visual monitoring of impairment (nystagmus) using IR cameras, but is limited to a single case and focuses on vestibular/neurological impairment rather than intoxication. The approach and technology are highly relevant for visual impairment detection, but not specifically for substance-induced intoxication.","{""device_description"": ""System consists of a commercially available mini-infrared camera (US $25, 1920x1080 resolution, 150° angle) mounted in 3D-printed goggles (US $13). Two cameras used for binocular recording."", ""operation"": ""Patient uses smartphone app to control camera and record eye movements during vertigo attacks in darkness. Videos are wirelessly transferred to smartphone for physician review."", ""analysis_method"": ""Eye movement waveforms extracted using OpenCV and corneal reflex method; nystagmus frequency and direction analyzed."", ""diagnostic_outcome"": ""Enabled diagnosis of lateral semicircular canal-type BPPV based on recorded nystagmus, which was not possible during standard outpatient assessment."", ""cost_effectiveness"": ""Device is significantly more affordable than traditional diagnostic tools; suitable for telemedicine and resource-limited settings."", ""limitations"": [""Single case study limits generalizability."", ""Camera resolution insufficient for detailed torsional nystagmus analysis."", ""Requires patient operation during vertigo, which may be challenging for some populations.""], ""future_directions"": [""Higher-resolution imaging."", ""Automated analysis."", ""Broader usability for older or dexterity-impaired patients.""], ""comparison_to_other_methods"": ""Overcomes limitations of smartphone-based recording in bright conditions (nystagmus suppression); more reliable for dark environment recording.""}"
https://www.frontiersin.org/journals/neurology/articles/10.3389/fneur.2024.1342108/full,ad0dde12-7ef3-4001-b2fb-170f386ded3a,ad0dde12-7ef3-4001-b2fb-170f386ded3a.json,"This paper presents a lightweight deep learning model for real-time video-based nystagmus tracking using ocular object segmentation. The model segments the sclera, iris, and pupil, detects blinks, and tracks pupil center to measure eye movements from standard video footage. It achieves high accuracy and fast inference speeds, outperforming existing open-source models. The approach is validated on both real and synthetic datasets, with strong correlation to ground truth nystagmus measurements. While primarily demonstrated for vertigo/vestibular impairment, the method is highly relevant for real-time visual impairment detection using standard RGB cameras.",Feasibility of video-based real-time nystagmus tracking: a lightweight deep learning model approach using ocular object segmentation,2024,"Frontiers in Neurology, doi:10.3389/fneur.2024.1342108",RGB,Eye,general impairment,Yes (validated at >90 FPS on consumer GPUs),"82,289 images (from real and synthetic datasets); nystagmus tracking validated on video from 1 BPPV patient (1,109 frames)","Clinical (hospital eye movement videos), synthetic (UnityEyes), and public datasets (OpenEDS); standard lighting (no IR/thermal)","Mean IoU (segmentation: up to 0.97), MAE (eye tracking: 0.42–0.59), F1 (blink: ≥0.95), correlation r=0.995 (nystagmus tracking)",⭐⭐⭐,"Highly relevant: real-time, camera-based (RGB) visual tracking of nystagmus for impairment detection, with strong performance and direct clinical applicability.","{""model_architecture"": ""Integrated deep learning pipeline with separate modules for ocular segmentation, blink detection, and pupil center tracking; all modules combined for nystagmus tracking."", ""datasets"": {""real"": ""HUSHH-SN and HUSHH-vHIT (clinical eye movement videos, N=1,568 patients)"", ""public"": ""OpenEDS (Meta, 11,639 images)"", ""synthetic"": ""UnityEyes (69,084 images)""}, ""segmentation_performance"": {""OpenEDS"": {""sclera"": 0.9743, ""iris"": 0.9601, ""pupil"": 0.9281}, ""HUSHH"": {""sclera"": 0.95, ""iris"": 0.9352, ""pupil"": 0.9073}}, ""eye_tracking_performance"": {""OpenEDS"": {""MAE"": 0.42, ""RMSE"": 0.53}, ""HUSHH"": {""MAE"": 0.59, ""RMSE"": 0.82}}, ""blink_detection_performance"": {""F1"": ""≥0.95"", ""AUC"": ""≥0.99""}, ""nystagmus_tracking_performance"": {""correlation_horizontal"": 0.9949, ""correlation_vertical"": 0.995}, ""execution_speed"": {""RTX3060"": ""94.59 FPS"", ""RTX A6000"": ""194.69 FPS""}, ""comparison_to_other_models"": ""Outperformed DeepVOG, EllSeg, and RITnet in segmentation accuracy and speed; superior generalization across datasets."", ""limitations"": [""Nystagmus tracking validated on a single BPPV patient video (proof-of-concept); larger clinical validation needed."", ""No direct alcohol/drug impairment detection—focus is on nystagmus/vestibular impairment."", ""No IR/thermal/depth modalities; only standard RGB video.""], ""future_work"": [""Expand to torsional nystagmus detection."", ""Enable smartphone/webcam compatibility."", ""External multi-institutional validation.""], ""conflicts_of_interest"": ""Some authors affiliated with NeuroEars, Inc. (model patent applications).""}"
https://formative.jmir.org/2025/1/e73811,8e6274e9-3571-4ad1-a5b1-f3bf1ff8ac00,8e6274e9-3571-4ad1-a5b1-f3bf1ff8ac00.json,"This paper presents the development and pilot evaluation of 'iCapNYS,' a smartphone app and eco-friendly cardboard goggle system for recording eye movements and head position during vertigo attacks. Using the iPhone's front camera and gyro sensor, the system enables patients to capture nystagmus episodes in real-world settings and share recordings with clinicians. The system's performance in detecting subtle nystagmus was found comparable to standard infrared video Frenzel glasses, though the study is limited to a single case. The approach is relevant for visual impairment detection via eye-movement analysis, but is focused on vestibular/vertigo-related impairment rather than intoxication.","Development of an Eco-Friendly Smartphone-Assisted Nystagmus Recording System for Recording Vertigo Attacks Anytime, Anywhere: Pilot App Development Study",2025,JMIR Formative Research,RGB,Eye,general impairment,"Yes (recording and immediate playback, but not automated real-time analysis)",1 (single case study),"Home, work, or any real-world setting (patient-operated, not restricted to clinic)",Qualitative comparison to infrared video Frenzel glasses (nystagmus frequency and slow-phase velocity),⭐,"The system uses camera-based eye-movement analysis for impairment detection, but is focused on vestibular/vertigo (not intoxication). It demonstrates relevant visual feature capture and real-world usability, but lacks direct application to intoxication or substance-induced impairment.","{""app_name"": ""iCapNYS"", ""hardware"": ""iPhone front camera, built-in gyro sensor, recyclable cardboard goggles"", ""recording_modes"": [""Manual (user-initiated start/stop)"", ""Automatic 90-second guided mode with voice prompts""], ""goggle_design"": ""Blocks ambient light, maintains optimal eye-camera alignment, easy assembly"", ""language_support"": [""Japanese"", ""English""], ""data_sharing"": ""Videos can be emailed to clinicians directly from the app"", ""comparison_baseline"": ""Infrared video Frenzel glasses (standard clinical tool)"", ""performance_notes"": ""Comparable nystagmus detection (frequency and slow-phase velocity) to clinical standard; subtle nystagmus detected in patient not visible to naked eye"", ""limitations"": [""Single patient case study"", ""No automated nystagmus detection/analysis (visual review only)"", ""Performance may vary with smartphone hardware and lighting"", ""Not designed for intoxication detection; focused on vertigo/vestibular disorders"", ""No IR/NIR capability (cannot record in complete darkness)""], ""ethics"": ""Approved by Mejiro University Medical Research Ethics Committee; informed consent obtained"", ""funding"": [""Japan Science and Technology Agency (JPMJPF2403)"", ""Japan Society for the Promotion of Science KAKENHI (23K08970)""]}"
https://ieeexplore.ieee.org/document/7153161,0c2cda9b-71a6-4e70-b97d-176c46e3e477,0c2cda9b-71a6-4e70-b97d-176c46e3e477.json,"This paper presents a method for detecting nystagmus (involuntary eye movement) using eye movement velocity from infrared video, primarily for vertigo diagnosis. The system uses an IR camera to record eye movements in a dark environment, extracts the pupil using adaptive thresholding and ellipse fitting, and computes eye movement velocity to detect nystagmus events. The method achieves an average accuracy of 87.21% on eight subjects. While not focused on intoxication, the approach is relevant for visual detection of impairment via eye movement analysis.",A New Method to Detect Nystagmus for Vertigo Diagnosis System by Eye Movement Velocity,2015,"14th IAPR International Conference on Machine Vision Applications (MVA), Tokyo, Japan",IR/NIR,Eye,general impairment,"Potential (frame rate 25 fps, but not explicitly real-time tested)","8 subjects, 3,260 images","Controlled, dark environment with IR camera and binocular mask",Accuracy rate (87.21%),⭐⭐,"The paper is relevant for visual impairment detection via eye movement, using IR video and pupil tracking. However, it is focused on vertigo/nystagmus rather than intoxication, and real-time capability is not explicitly demonstrated.","{""pupil_extraction_method"": ""Adaptive thresholding, blackest blob detection, ellipse fitting"", ""nystagmus_detection_criterion"": ""Eye movement velocity exceeding 6 pixels/second"", ""frame_rate"": ""25 fps"", ""image_resolution"": ""320x240 pixels"", ""hardware"": ""MD-Tech USB IR camera (MDC-9), mounted on binocular mask"", ""evaluation_method"": ""Comparison with expert manual annotation of nystagmus events"", ""error_sources"": [""Difficulty of manual counting by expert"", ""Imprecise pupil center extraction due to noise""], ""limitations"": [""Not tested for intoxication-induced impairment"", ""Not explicitly real-time in deployment"", ""Small sample size""]}"
https://pmc.ncbi.nlm.nih.gov/articles/PMC6886135/,6f747d73-6386-4b3b-833d-428f72cf3c07,6f747d73-6386-4b3b-833d-428f72cf3c07.json,"This comprehensive review summarizes the ophthalmic effects of various illicit drugs, including alcohol, cannabis, opioids, stimulants, and hallucinogens. It details visual and ocular manifestations such as changes in pupil size, nystagmus, impaired oculomotor function, and other eye-related symptoms. The paper highlights the potential of thermal infrared imaging for alcohol intoxication detection but does not present original real-time camera-based detection systems or algorithms. The review is valuable for understanding which visual features are affected by intoxication and could inform future camera-based detection research.",Illicit drugs: Effects on eye,2019,Indian Journal of Medical Research,"Thermal, RGB",Eye,"alcohol, cannabis, opioids, stimulants, hallucinogens, general impairment",No (review article; mentions potential for real-time detection via thermal imaging but does not implement or evaluate it),N/A (review article),Clinical and general (review of literature; not a specific experimental setting),N/A (no experimental results),⭐⭐,"The paper provides a detailed review of visual features affected by intoxication and mentions the use of thermal imaging for alcohol detection, but does not present or evaluate real-time camera-based detection systems.","{""thermal_imaging_for_alcohol"": ""Cites a study (Koukiou & Anastassopoulos, 2016) showing that eye thermal signatures (sclera vs. iris temperature) can be used to screen for alcohol intoxication using infrared imaging."", ""visual_features_by_substance"": {""alcohol"": [""dilated pupils"", ""slower pupillary reaction"", ""nystagmus"", ""diplopia"", ""night vision disturbances"", ""decreased contrast sensitivity"", ""twitching of eyelid (myokymia)"", ""impaired visuospatial orientation""], ""cannabis"": [""dilated pupils"", ""conjunctival injection"", ""reduced accommodation amplitude"", ""impaired oculomotor function (saccades, smooth pursuit)"", ""impaired visuospatial working memory""], ""opioids"": [""miosis (constricted pupils)"", ""decreased velocity of pupillary constriction"", ""nystagmus"", ""disturbance of eye fixation"", ""saccadic intrusions"", ""oscillations""], ""stimulants (cocaine, amphetamines, methamphetamine)"": [""dilated pupils"", ""cycloplegia"", ""exophthalmos"", ""retraction of upper eyelid"", ""retinal vascular occlusive disease""], ""hallucinogens"": [""dilated pupils"", ""nystagmus (phencyclidine)"", ""oculogyric crisis""]}, ""limitations"": [""No original experimental data or real-time detection system presented."", ""Non-visual methods (e.g., urine tests, clinical examination) are discussed but not relevant for camera-based detection.""], ""tables_summary"": {""Table I"": ""Lists frequent ophthalmic or visual manifestations and the most commonly abused drugs causing them (e.g., diplopia, dry eye, mydriasis, miosis, nystagmus, impaired oculomotor function)."", ""Table II"": ""Summarizes effects of abusive drugs on ocular motility and pupil (e.g., pupil size, pupillary reaction to light, presence of nystagmus, ocular convergence).""}, ""notable_references"": [""Koukiou G, Anastassopoulos V. Drunk person screening using eye thermal signatures. J Forensic Sci 2016; 61: 259-64.""]}"
https://pmc.ncbi.nlm.nih.gov/articles/PMC4545665/,2dceb668-bffe-4d0b-a568-6d84ee305341,2dceb668-bffe-4d0b-a568-6d84ee305341.json,"This comprehensive review details the ocular and neuro-ophthalmic effects of various drugs and alcohol, describing a wide range of visual manifestations associated with substance abuse. While the paper provides valuable clinical insights into how intoxication and drug use affect the eyes and visual system, it does not focus on camera-based or computer vision methods for intoxication detection. The information is relevant for understanding visual biomarkers that could be targeted by vision-based systems, but the paper itself does not present or evaluate any such technologies.",Ocular manifestations of drug and alcohol abuse,2013,"Current Opinion in Ophthalmology, 24(6):566–573. doi:10.1097/ICU.0b013e3283654db2",No Camera,Eye,"alcohol, cannabis, opioids, general impairment, mixed",No,"Review article (multiple referenced studies, not a primary dataset)",Clinical/medical literature review,N/A,⭐,"The paper provides a detailed clinical overview of ocular effects of substance abuse, which may inform the selection of visual features for camera-based intoxication detection, but it does not present or evaluate any camera-based or computer vision methods.","{""ocular_manifestations"": {""alcohol"": [""dry eye"", ""fetal alcohol syndrome (optic nerve hypoplasia, strabismus, abnormal saccades)"", ""ocular trauma"", ""diplopia"", ""Wernicke’s encephalopathy""], ""methanol"": [""toxic optic neuropathy""], ""cocaine"": [""corneal anesthesia"", ""keratitis"", ""corneal ulceration"", ""mydriasis"", ""retinal emboli"", ""retinal venous occlusion"", ""orbital disease"", ""stroke"", ""hallucinations""], ""methamphetamine"": [""keratitis"", ""corneal ulceration"", ""mydriasis"", ""retinal venous occlusion"", ""intraretinal hemorrhage"", ""talc retinopathy"", ""stroke"", ""hallucinations""], ""heroin/methadone"": [""talc retinopathy"", ""endophthalmitis"", ""miosis""], ""marijuana"": [""conjunctival injection"", ""decreased intraocular pressure"", ""nystagmus"", ""hallucinations""], ""LSD"": [""mydriasis"", ""hallucinations"", ""palinopsia""], ""phencyclidine"": [""decreased corneal reflex"", ""diplopia"", ""nystagmus""], ""bath salts"": [""mydriasis""], ""alkyl nitrites"": [""maculopathy""], ""barbiturates"": [""ptosis"", ""diplopia"", ""nystagmus""]}, ""notable_visual_features"": [""Pupil size and reactivity (miosis, mydriasis)"", ""Nystagmus (horizontal, pendular, etc.)"", ""Strabismus and abnormal saccades"", ""Conjunctival injection"", ""Corneal changes (ulceration, anesthesia)"", ""Retinal changes (talc retinopathy, maculopathy, hemorrhage)"", ""Optic nerve changes (edema, atrophy)""], ""limitations"": [""No camera-based or computer vision methods are discussed."", ""No real-time detection or automated analysis is presented."", ""Focus is on clinical findings and case reports.""], ""potential_relevance_for_vision_systems"": [""Describes visual biomarkers (e.g., pupil dynamics, nystagmus, conjunctival injection) that could be targeted by camera-based intoxication detection systems.""]}"
https://thegrenze.com/pages/servej.php?fn=793.pdf&name=Drugged%20Eye%20Detection%20using%20Image%20Processing&id=3529&association=GRENZE&journal=GIJET&year=2024&volume=10&issue=2,b4eb715f-09c7-461a-ba1a-2bfe4f6750b7,b4eb715f-09c7-461a-ba1a-2bfe4f6750b7.json,"This paper presents a non-invasive, image-based method for detecting drug-induced impairment by analyzing sclera (white of the eye) patterns using RGB images. The approach employs K-Nearest Neighbors (KNN) classification and Local Binary Pattern (LBP) feature extraction to distinguish between drugged and non-drugged eyes. The system is designed for rapid, automated detection and is tested on images captured under various lighting and environmental conditions. Results indicate high accuracy and real-time capability, making it relevant for practical intoxication detection using standard cameras.",Drugged Eye Detection using Image Processing,2024,"Grenze International Journal of Engineering and Technology, June Issue",RGB,Eye,general impairment,Yes (results within seconds),"Not explicitly stated; images of both drug-influenced and healthy eyes, multiple rounds of testing",Various lighting and environmental conditions; images captured with mobile phone or digital camera,"Accuracy (qualitative: 'notably high', especially for non-drugged eyes; no explicit percentage reported)",⭐⭐⭐,"Directly addresses real-time, camera-based detection of drug-induced impairment using visual features of the eye; uses standard RGB cameras and automated image processing.","{""algorithm"": ""K-Nearest Neighbors (KNN) classifier"", ""feature_extraction"": ""Local Binary Pattern (LBP) for texture analysis of sclera"", ""image_preprocessing"": [""Noise reduction"", ""Image resizing"", ""Thresholding"", ""Binary conversion""], ""image_acquisition"": ""Images captured using mobile phone or digital camera in JPG format, under different angles and lighting conditions"", ""classification_labels"": [""Normal"", ""Drugged""], ""segmentation"": ""Sclera region segmented and analyzed for color and texture changes"", ""output"": ""Binary classification (Drugged/Not Drugged)"", ""limitations"": ""No explicit quantitative accuracy reported; sample size not specified; only sclera-based features considered; does not specify which drugs or levels of impairment are detected; non-visual methods not used."", ""processing_time"": ""Few seconds per image"", ""data_handling"": ""Randomized training/testing splits, five rounds of verification per training file""}"
https://www.medrxiv.org/content/10.1101/2023.10.12.23296882v1.full,36c21811-d3b7-42a6-b2a0-01c7023f63a2,36c21811-d3b7-42a6-b2a0-01c7023f63a2.json,"This comprehensive review paper surveys the state-of-the-art in remote photoplethysmography (rPPG) for non-contact measurement of heart rate (HR) and blood oxygen saturation (SpO2) using camera-based systems. It covers a wide range of camera modalities (RGB, IR, Thermal, Depth), visual features (skin color changes, ROI selection), and experimental setups, with a focus on the technical challenges, limitations, and future directions for real-world deployment. The review does not address intoxication or impairment detection, but the methods discussed (especially rPPG via facial video) are foundational for camera-based physiological monitoring, which could be relevant for impairment detection if combined with other features.",Remote Photoplethysmography (rPPG): A State-of-the-Art Review,2023,IEEE Reviews in Biomedical Engineering,"RGB, IR/NIR, Thermal",Skin Color,,"Varies by study; some real-time, many offline or lab-based","Varies widely; most studies n<20, a few up to n=117",Primarily lab/controlled; very few in home/real-world settings,"Root Mean Square Error (RMSE), r-correlation, Standard Deviation Error (σ)",⭐,"The review is foundational for camera-based physiological monitoring (HR, SpO2) but does not address intoxication/impairment detection directly. However, rPPG methods could be adapted as physiological features in future impairment detection systems.","{""review_scope"": ""Comprehensive survey of rPPG for HR and SpO2 using camera-based systems (RGB, IR, Thermal, Depth, smartphone, webcam, Kinect, etc.)"", ""technical_process"": [""Face/ROI detection (manual, Viola-Jones, neural networks, KLT tracking)"", ""Signal extraction (RGB/IR/thermal pixel averaging)"", ""Noise reduction (PCA, ICA, BSS, spatial pooling)"", ""Frequency analysis (FFT, bandpass filtering)"", ""Vital sign extraction (peak detection, ratiometric SpO2 calculation)""], ""equipment_types"": [""Webcam"", ""Smartphone camera"", ""Thermal camera"", ""CCD camera"", ""Kinect (RGB, IR, Depth)""], ""limitations"": [""Most studies in controlled/lab settings; lack of real-world/clinical validation"", ""Small, non-diverse participant samples (few with dark skin, makeup, facial hair)"", ""ROI occlusion and movement artifacts not fully addressed"", ""Expensive equipment (thermal, CCD) not practical for wide deployment"", ""No direct application to intoxication/impairment detection""], ""datasets"": [""PURE"", ""MAHNOB-HCI"", ""COHFACE"", ""MMSE-HR"", ""BH-rPPG"", ""MPSC-rPPG"", ""UBFC-RPPG"", ""ARPOS""], ""notable_findings"": [""Green channel often provides strongest rPPG signal"", ""ROI selection and tracking critical for robustness"", ""Movement, illumination, and skin pigmentation significantly affect accuracy"", ""No commercially available, clinically validated rPPG system for remote HR/SpO2""], ""future_directions"": [""Validation in real-world/clinical environments"", ""Inclusion of diverse participant demographics"", ""Robustness to movement, occlusion, and lighting"", ""Open datasets with realistic scenarios""], ""relevance_to_intoxication_detection"": ""While not directly addressing intoxication, rPPG-derived physiological features (e.g., abnormal HR, SpO2) could be integrated with other visual cues for impairment detection in future research.""}"
https://arxiv.org/html/2510.09916v1,78784172-0e98-4394-8b24-c502900a73b4,78784172-0e98-4394-8b24-c502900a73b4.json,"This paper presents a smartwatch-based system for real-time detection of alcohol intoxication using accelerometer, gyroscope, and heart rate data. The study collected data from 30 participants over three weeks, focusing on periods where transdermal alcohol concentration (TAC) exceeded legal intoxication thresholds. Multiple machine learning models were evaluated for their accuracy and efficiency on mobile devices, with 1D-CNN and Hyperdimensional Computing (HDC) models showing the best balance of performance and resource usage. The system is designed for just-in-time adaptive interventions (JITAIs), providing real-time notifications to users when intoxication is detected.",Advancing Intoxication Detection: A Smartwatch-Based Approach,2025,arXiv:2510.09916v1 [cs.LG],No Camera,Gait,alcohol,Yes (demonstrated on smartwatch/smartphone with sub-second inference times for best models),30 participants (14 with qualifying intoxication sessions),"Naturalistic, real-world (participants' daily lives, both in-person and remote monitoring)","Accuracy (76.1% for HDC and 1D-CNN), ROC-AUC (0.748 for 1D-CNN), F1 score (0.665 for HDC)",⭐,No camera-based (visual) modalities or features are used; all sensing is via inertial and physiological (heart rate) data from wearables. Visual methods are only mentioned in related work as limitations.,"{""sensors_used"": [""Accelerometer (Apple Watch Series 8)"", ""Gyroscope (Apple Watch Series 8)"", ""Heart rate (Apple Watch Series 8)"", ""Transdermal alcohol concentration (BACtrack Skyn, used as ground truth/label)""], ""data_collection_frequency"": ""50 Hz (downsampled to 40 Hz after filtering)"", ""session_definition"": ""Continuous recording >1 minute with all devices operational"", ""windowing"": ""20-second windows for feature extraction and classification"", ""machine_learning_models_evaluated"": [""SVM"", ""LightGBM"", ""bi-LSTM"", ""GRU"", ""Transformer"", ""1D-CNN"", ""Hyperdimensional Computing (HDC)""], ""best_models"": [{""model"": ""1D-CNN"", ""accuracy"": ""76.1%"", ""ROC-AUC"": ""0.748"", ""F1"": ""0.655"", ""model_size_MB"": ""0.035"", ""inference_time_s"": ""0.0121""}, {""model"": ""HDC"", ""accuracy"": ""76.1%"", ""ROC-AUC"": ""0.744"", ""F1"": ""0.665"", ""model_size_MB"": ""36.7"", ""inference_time_s"": ""0.0842""}], ""deployment"": ""Prototype Android app using PyTorch Executorch on Samsung Galaxy S20"", ""JITAI_functionality"": ""Real-time notifications and interventions (e.g., ride-share suggestion) when intoxication detected"", ""limitations"": [""No camera or visual features; only inertial and physiological data"", ""Visual methods (e.g., facial temperature) only referenced in related work"", ""Sample size for intoxicated sessions limited to 14 participants""], ""future_work"": [""Expand dataset for greater generalizability"", ""Optimize models for even lower resource usage"", ""Explore integration with other behavioral health monitoring""]}"
https://www.mdpi.com/2076-3417/15/15/8509,da4a8aeb-2267-46da-8807-285437fc6b5d,da4a8aeb-2267-46da-8807-285437fc6b5d.json,"This paper presents a comprehensive study on non-contact vital sign estimation (heart rate, SpO2, respiratory rate) using RGB cameras on smartphones and laptops. The authors propose a robust method combining color difference signal amplification and the POS algorithm, validated across diverse devices and lighting conditions. While the work demonstrates real-time face detection and signal extraction, it focuses on general health monitoring and does not address intoxication or impairment detection. The study is highly relevant for camera-based physiological monitoring but only indirectly relates to intoxication detection, as it does not analyze visual features or behaviors specific to impairment.",Camera-Based Vital Sign Estimation Techniques and Mobile App Development,2025,"Applied Sciences (MDPI), 15, 8509. https://doi.org/10.3390/app15158509",RGB,Skin Color,general impairment,Yes (real-time face detection and signal extraction demonstrated),"20 subjects, 508 video sequences (aged 21–61)","Various (indoor, sunlight, fluorescent, LED; multiple smartphones and webcams)","Mean Absolute Error (MAE), Root Mean Square Error (RMSE), Bland–Altman plots, accuracy rate (>88% for HR detection)",⭐,"The paper is focused on real-time camera-based physiological monitoring (HR, SpO2, RR) but does not address intoxication or impairment detection via visual cues. It is foundational for non-contact vital sign estimation, which could be a component in impairment detection, but does not analyze intoxication-specific visual features.","{""proposed_methods"": [""CA-POS (Color Amplification + Plane-Orthogonal-to-Skin) for HR detection"", ""SpO2 estimation using green and blue channel absorption ratios"", ""Respiratory rate via rPPG frequency analysis""], ""device_diversity"": [""Galaxy A50, A9, Note 9, S21 Plus"", ""iPhone X"", ""Logitech C270, MS HD-3000 webcams"", ""LG Gram, MacBook Air laptops""], ""lighting_conditions"": [""Sunlight"", ""Fluorescent (3200K, 5600K)"", ""LED""], ""face_detection"": ""AdaBoost algorithm for real-time ROI selection"", ""validation"": [""Compared with contact pulse oximeter and reference sensors"", ""Bland–Altman analysis for agreement""], ""mobile_app"": ""Developed using React Native; supports HR, SpO2, RR measurement and history tracking"", ""limitations"": [""No direct analysis of intoxication/impairment-specific visual features"", ""Motion artifacts not fully addressed"", ""Empirical parameter tuning"", ""Limited database diversity (mainly healthy adults)""], ""future_work"": [""Automated scaling for color amplification"", ""Improved SpO2 estimation"", ""Larger, more diverse datasets (including skin tone variation)"", ""Integration of deep learning for artifact removal""]}"
https://openaccess.thecvf.com/content/WACV2025W/HAVI/papers/Bouraffa_Deep_Learning-based_rPPG_Models_towards_Automotive_Applications_A_Benchmark_Study_WACVW_2025_paper.pdf,1f8b7072-995a-4874-8487-96d9eaa42d87,1f8b7072-995a-4874-8487-96d9eaa42d87.json,"This paper presents a comprehensive benchmark of deep learning and traditional rPPG (remote photoplethysmography) algorithms for non-contact heart rate (HR) and respiration rate (RR) estimation in automotive environments using in-cabin RGB and NIR cameras. The study evaluates multiple supervised and unsupervised models on the MR-NIRP car dataset, which includes real driving and garage scenarios with varying motion and lighting. Results show that deep learning models, especially PhysNet and PhysFormer, outperform traditional methods for HR estimation, but RR estimation remains challenging. The work is highly relevant for real-time, camera-based driver impairment and health monitoring, though it focuses on physiological signals (HR, RR) as proxies for impairment (e.g., fatigue, sudden illness) rather than direct intoxication detection.",Deep Learning-based rPPG Models towards Automotive Applications: A Benchmark Study,2024,WACV Workshop / Computer Vision Foundation / IEEE Xplore (Open Access version),"RGB, IR/NIR",Facial Color Change,"fatigue, general impairment",Yes (focus on real-time and on-device models),"MR-NIRP: 18 participants (16 male, 2 female, ages 25-60); also uses PURE, UBFC-rPPG, SCAMPS datasets for cross-validation","In-vehicle (driving in urban environments and garage, with variable lighting and motion conditions)","MAE, RMSE, MAPE, SNR, Pearson correlation (ρ) for HR and RR estimation",⭐⭐⭐,"Highly relevant as it benchmarks real-time, camera-based physiological monitoring (HR, RR) in real driving conditions, directly applicable to visual driver impairment detection systems. While not focused on intoxication per se, the methods and findings are foundational for camera-based impairment detection.","{""algorithms_benchmarked"": {""unsupervised"": [""ICA"", ""POS"", ""CHROM"", ""GREEN"", ""LGI"", ""PBV""], ""supervised"": [""DeepPhys"", ""TS-CAN"", ""EfficientPhys-C"", ""PhysNet"", ""PhysFormer""]}, ""dataset_details"": {""MR-NIRP"": {""participants"": 18, ""modalities"": [""RGB"", ""NIR""], ""frame_rate"": ""30 Hz"", ""ground_truth"": ""finger pulse oximeter (60 Hz)"", ""scenarios"": [""garage (engine running)"", ""urban driving (day/night, sunny/overcast)""], ""motion_conditions"": [""still"", ""small motion"", ""large motion""]}, ""other_datasets"": [""PURE"", ""UBFC-rPPG"", ""SCAMPS""]}, ""preprocessing"": {""face_detection"": ""RetinaFace (NN models), MediaPipe FaceMesh (unsupervised)"", ""ROI"": ""entire face, cropped and resized"", ""frame_normalization"": ""difference-normalized frames for NN models""}, ""postprocessing"": {""signal_reconstruction"": ""cumulative sum for difference-normalized signals"", ""filtering"": ""Butterworth bandpass (HR: 0.75-2.5 Hz, RR: 0.08-0.5 Hz)"", ""frequency_analysis"": ""FFT, PSD""}, ""key_findings"": {""HR_estimation"": ""PhysNet (NN) outperforms all others, robust to motion and lighting; LGI and POS best among unsupervised"", ""RR_estimation"": ""PhysNet and PhysFormer best among NN, but ICA (unsupervised) sometimes outperforms in RMSE; RR estimation remains challenging"", ""cross_dataset"": ""Models trained on non-automotive datasets perform poorly in real driving, highlighting need for in-vehicle data""}, ""limitations"": [""Focuses on physiological proxies (HR, RR) for impairment, not direct intoxication detection"", ""Sample size limited (18 subjects in MR-NIRP)"", ""No direct alcohol/cannabis impairment data; only fatigue/general impairment via physiological signals"", ""NIR modality not fully benchmarked in this study (focus is on RGB for most models)""], ""code_availability"": ""Integrated with open-source rPPG-toolbox (PyTorch); GitHub link provided in paper"", ""future_work"": [""Expand dataset diversity (more subjects, scenarios)"", ""Include NIR alongside RGB for comprehensive benchmarks"", ""Advanced data augmentation/meta-learning for better generalization"", ""Directly address intoxication detection (alcohol, drugs) in future studies""]}"
https://www.mdpi.com/2076-3417/13/3/1390,1c4d4a42-c18c-41a4-b61a-77157f8057c5,1c4d4a42-c18c-41a4-b61a-77157f8057c5.json,"This paper presents a markerless, vision-based method for detecting alcohol-induced impairment using gait analysis from RGB video. The approach uses background subtraction, gait energy images (GEI), and a convolutional neural network (CNN) to classify 'drunk' versus 'sober' walking, with data augmentation to address limited sample size. The method achieved an average accuracy of ~75% on 20 participants simulating intoxication with impairment goggles. The study demonstrates the feasibility of real-time, non-contact intoxication detection in controlled environments, but notes limitations in generalizability and the need for larger, more diverse datasets.",A Deep-Learning Approach for Identifying a Drunk Person Using Gait Recognition,2023,"Applied Sciences (MDPI), https://doi.org/10.3390/app13031390",RGB,Gait,alcohol,Potential for real-time; tested offline but designed for real-time application,"20 participants (10 sober and 10 simulated drunk walks per participant, using impairment goggles)","Outdoor, shaded area, controlled lighting (3000 lux), flat unobstructed surface","Validation accuracy (average 74.94%, range 63.5%–92.75%)",⭐⭐⭐,"Highly relevant: direct use of RGB camera for real-time, non-contact intoxication detection via gait analysis; method is markerless and does not require subject cooperation or wearable sensors.","{""methodology"": {""background_subtraction"": ""MOG2 algorithm with morphological opening to remove noise"", ""gait_representation"": ""Gait Energy Image (GEI) computed from background-subtracted silhouettes"", ""augmentation"": ""Image augmentation (scaling, rotation, flipping) to increase dataset size by 10x"", ""deep_learning"": ""Custom CNN architecture, optimized for dropout rate, kernel size, and epochs""}, ""experimental_setup"": {""camera"": ""Samsung Galaxy S21+ rear camera, UHD 30 fps, 3840x2160 resolution"", ""recording_distance"": ""Camera placed 5m from subject, 1.2m above ground, capturing 4m of a 10m walk"", ""simulated_intoxication"": ""Drunk Busters Goggles used to simulate alcohol impairment""}, ""gait_parameters"": {""stride_time"": ""13% longer in drunk condition"", ""stride_length"": ""13% shorter in drunk condition"", ""stride_velocity"": ""22% slower in drunk condition""}, ""limitations"": [""Small sample size (20 participants)"", ""Simulated intoxication (goggles) rather than actual alcohol consumption"", ""Controlled outdoor environment only; not tested at night or in complex backgrounds"", ""Requires prior sober gait data for comparison; generalization to unknown subjects not demonstrated""], ""future_work"": [""Testing in diverse environments (night, indoor, adverse weather)"", ""Larger and more diverse participant pool"", ""Generalization to unknown subjects without prior sober data"", ""Exploration of other machine learning models (e.g., RNNs for time-series analysis)""], ""ethics"": {""IRB_approval"": ""Kyung Hee University Bioethics Review Board (KHGIRB-21-287)"", ""informed_consent"": ""Obtained from all participants""}}"